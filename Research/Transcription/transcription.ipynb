{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-12T09:32:34.052669Z",
     "start_time": "2025-11-12T09:31:43.323031Z"
    }
   },
   "source": [
    "# FOR ANASS\n",
    "\n",
    "import whisper\n",
    "import whisperx\n",
    "import librosa\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "# -------------------------------\n",
    "# Helper Functions\n",
    "# -------------------------------\n",
    "\n",
    "def load_models(device=\"cpu\", whisper_model_size=\"medium\"):\n",
    "    \"\"\"Load Whisper and WhisperX alignment models.\"\"\"\n",
    "    model_whisper = whisper.load_model(whisper_model_size, device=device)\n",
    "    return model_whisper, device\n",
    "\n",
    "def transcribe_audio(model_whisper, audio_file, prompt_text=\"\", device=\"cpu\"):\n",
    "    \"\"\"Transcribe audio using Whisper with optional prompt.\"\"\"\n",
    "    result = model_whisper.transcribe(audio_file, prompt=prompt_text)\n",
    "    language = result.get(\"language\", \"en\")\n",
    "    return result, language\n",
    "\n",
    "def align_transcript(result_whisper, language_code, audio_file, device=\"cpu\"):\n",
    "    \"\"\"Align Whisper transcript with WhisperX to get word-level info.\"\"\"\n",
    "    alignment_model, align_metadata = whisperx.load_align_model(\n",
    "        language_code=language_code, device=device\n",
    "    )\n",
    "    audio, sr = librosa.load(audio_file, sr=16000, mono=True)\n",
    "    duration_sec = len(audio) / sr\n",
    "    result_aligned = whisperx.align(\n",
    "        transcript=result_whisper[\"segments\"],\n",
    "        model=alignment_model,\n",
    "        align_model_metadata=align_metadata,\n",
    "        audio=audio,\n",
    "        device=device,\n",
    "        return_char_alignments=False\n",
    "    )\n",
    "    return result_aligned, audio, sr, duration_sec\n",
    "\n",
    "def compute_pause_stats(word_segments):\n",
    "    \"\"\"Compute average pause and total silence between words.\"\"\"\n",
    "    pauses = []\n",
    "    total_silence = 0.0\n",
    "    for i in range(1, len(word_segments)):\n",
    "        prev_end = word_segments[i-1]['end']\n",
    "        curr_start = word_segments[i]['start']\n",
    "        pause_dur = curr_start - prev_end\n",
    "        if pause_dur > 0:\n",
    "            pauses.append(pause_dur)\n",
    "            total_silence += pause_dur\n",
    "    avg_pause = np.mean(pauses) if pauses else 0.0\n",
    "    return avg_pause, total_silence\n",
    "\n",
    "def detect_fillers(word_segments, language_code):\n",
    "    \"\"\"Count filler words in the transcript, ignoring punctuation, and return detected fillers.\"\"\"\n",
    "\n",
    "    # Expanded English filler words\n",
    "    filler_words_en = {\n",
    "        \"to be honest\", \"kind of\", \"um\", \"ah\", \"huh\", \"and so\", \"so um\", \"uh\",\n",
    "        \"and um\", \"like um\", \"so like\", \"like it's\", \"it's like\", \"i mean\", \"yeah\",\n",
    "        \"ok so\", \"uh so\", \"so uh\", \"yeah so\", \"you know\", \"it's uh\", \"uh and\",\n",
    "        \"and uh\", \"like\", \"kind\", \"well\", \"actually\", \"basically\", \"literally\",\n",
    "        \"you see\", \"right\", \"so\", \"okay\", \"alright\", \"you know what I mean\",\n",
    "        \"I guess\", \"I think\", \"I mean\", \"anyway\", \"just\", \"so yeah\", \"so okay\",\n",
    "        \"umm\", \"hmm\"\n",
    "    }\n",
    "\n",
    "    # Expanded Dutch filler words\n",
    "    filler_words_nl = {\n",
    "        \"eh\", \"uh\", \"uuh\", \"uhm\", \"euh\", \"zeg maar\", \"weet je\", \"dus\", \"nou\",\n",
    "        \"toch\", \"zeg maar even\", \"eigenlijk\", \"soort van\", \"om het zo te zeggen\",\n",
    "        \"weet je wel\", \"ja\", \"oké\", \"nou ja\", \"hè\", \"inderdaad\", \"juist\", \"precies\",\n",
    "        \"dus ja\", \"maar ja\", \"zeg\", \"ehm\", \"hm\", \"ok\", \"oké dan\"\n",
    "    }\n",
    "\n",
    "    filler_list = filler_words_nl if language_code.startswith(\"nl\") else filler_words_en\n",
    "\n",
    "    # Remove punctuation from each word for comparison\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    words_text = [w['word'].strip().lower().translate(translator) for w in word_segments]\n",
    "\n",
    "    filler_count = 0\n",
    "    detected_fillers = []\n",
    "\n",
    "    for filler in filler_list:\n",
    "        # Split filler into tokens and remove punctuation from tokens\n",
    "        tokens = [t.translate(translator) for t in filler.lower().split()]\n",
    "        n = len(tokens)\n",
    "        for i in range(len(words_text) - n + 1):\n",
    "            if words_text[i:i+n] == tokens:\n",
    "                filler_count += 1\n",
    "                # Save the detected filler as it appears in the transcript (cleaned)\n",
    "                detected_fillers.append(\" \".join(words_text[i:i+n]))\n",
    "\n",
    "    filler_percentage = (filler_count / len(words_text)) * 100 if words_text else 0\n",
    "\n",
    "    return filler_count, filler_percentage, detected_fillers\n",
    "\n",
    "def extract_word_info(word_segments, confidence_threshold=0.7):\n",
    "    \"\"\"Extract word-level text, timestamps, and confidence scores.\"\"\"\n",
    "    word_data = []\n",
    "    low_conf_words = []\n",
    "    all_confidences = []\n",
    "\n",
    "    for word in word_segments:\n",
    "        text = word['word'].strip()\n",
    "        start = word['start']\n",
    "        end = word['end']\n",
    "        confidence = float(word.get('score', word.get('confidence', 0.5)))\n",
    "        all_confidences.append(confidence)\n",
    "        if confidence < confidence_threshold:\n",
    "            low_conf_words.append((text, confidence, start))\n",
    "        word_data.append({\n",
    "            \"word\": text,\n",
    "            \"start\": start,\n",
    "            \"end\": end,\n",
    "            \"confidence\": confidence\n",
    "        })\n",
    "    return word_data, all_confidences, low_conf_words\n",
    "\n",
    "# -------------------------------\n",
    "# Main Pipeline Function\n",
    "# -------------------------------\n",
    "\n",
    "def process_audio(audio_file, prompt_text=\"\", device=\"cpu\"):\n",
    "    # Load models\n",
    "    model_whisper, device = load_models(device=device)\n",
    "\n",
    "    # Transcribe\n",
    "    result_whisper, language_code = transcribe_audio(model_whisper, audio_file, prompt_text, device)\n",
    "\n",
    "    # Align word-level transcript\n",
    "    result_aligned, audio, sr, duration_sec = align_transcript(result_whisper, language_code, audio_file, device)\n",
    "\n",
    "    # Word-level info\n",
    "    word_data, all_confidences, low_conf_words = extract_word_info(result_aligned[\"word_segments\"])\n",
    "\n",
    "    # Pause / silence\n",
    "    avg_pause, total_silence = compute_pause_stats(result_aligned[\"word_segments\"])\n",
    "\n",
    "    # Filler words\n",
    "    filler_count, filler_percentage, detected_fillers = detect_fillers(result_aligned[\"word_segments\"], language_code)\n",
    "\n",
    "    # Compile transcript\n",
    "    transcript_text = \" \".join([w['word'].strip() for w in result_aligned[\"word_segments\"]])\n",
    "    transcript_text = \" \".join(transcript_text.split())\n",
    "\n",
    "    return {\n",
    "        \"transcript\": transcript_text,\n",
    "        \"word_data\": word_data,\n",
    "        \"avg_pause\": avg_pause,\n",
    "        \"total_silence\": total_silence,\n",
    "        \"filler_count\": filler_count,\n",
    "        \"filler_percentage\": filler_percentage,\n",
    "        \"detected_fillers\": detected_fillers,\n",
    "        \"language\": language_code\n",
    "    }\n",
    "\n",
    "# -------------------------------\n",
    "# Example Usage\n",
    "# -------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    audio_file = \"audio/TestAudio.m4a\"\n",
    "    prompt_text = \"Fontys University, Eindhoven, Netherlands\"\n",
    "\n",
    "    results = process_audio(audio_file, prompt_text)\n",
    "\n",
    "    print(f\"\\nDetected language: {results['language']}\")\n",
    "    print(f\"Transcript:\\n{results['transcript']}\")\n",
    "    print(f\"\\n--- Word-Level Info ---\")\n",
    "    for w in results['word_data']:\n",
    "        print(f\"[{w['start']:.2f}-{w['end']:.2f}] {w['word']} (conf: {w['confidence']:.3f})\")\n",
    "\n",
    "    print(f\"\\n--- Pause & Filler Stats ---\")\n",
    "    print(f\"Average pause: {results['avg_pause']:.2f}s\")\n",
    "    print(f\"Total silence: {results['total_silence']:.2f}s\")\n",
    "    print(f\"Filler words count: {results['filler_count']}\")\n",
    "    print(f\"Filler word %: {results['filler_percentage']:.2f}%\")\n",
    "    print(f\"Filler words: {results['detected_fillers']}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anass_de_programmeur\\School\\Reflect_Audio_Journaling\\Research\\Transcription\\.venv\\lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "C:\\Users\\anass\\AppData\\Local\\Temp\\ipykernel_2808\\1102382576.py:29: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio, sr = librosa.load(audio_file, sr=16000, mono=True)\n",
      "C:\\Anass_de_programmeur\\School\\Reflect_Audio_Journaling\\Research\\Transcription\\.venv\\lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected language: en\n",
      "Transcript:\n",
      "Today I woke up, brushed my teeth, got dressed up and went out. I study at Fontys University. The first lecture was about machine learning and AI. To be honest, I didn't understand much about it. Then it was time for lunch. I went to the store with my friends and got like a sandwich. Then we went back together. In the evening I met with my friend Preslavan and yes, so we had a fun night out drinking cocktails and eating fries.\n",
      "\n",
      "--- Word-Level Info ---\n",
      "[0.00-1.21] Today (conf: 0.707)\n",
      "[1.23-1.25] I (conf: 0.999)\n",
      "[1.29-1.97] woke (conf: 0.724)\n",
      "[2.15-2.25] up, (conf: 0.918)\n",
      "[2.56-2.86] brushed (conf: 0.857)\n",
      "[2.94-3.08] my (conf: 0.996)\n",
      "[3.18-3.54] teeth, (conf: 0.712)\n",
      "[4.14-4.33] got (conf: 0.989)\n",
      "[4.41-4.77] dressed (conf: 0.919)\n",
      "[4.91-4.99] up (conf: 0.990)\n",
      "[5.17-5.29] and (conf: 0.779)\n",
      "[5.39-5.59] went (conf: 0.962)\n",
      "[5.77-5.91] out. (conf: 0.999)\n",
      "[6.54-6.60] I (conf: 0.995)\n",
      "[6.66-6.94] study (conf: 0.599)\n",
      "[6.96-7.00] at (conf: 0.275)\n",
      "[6.98-7.48] Fontys (conf: 0.859)\n",
      "[7.54-8.29] University. (conf: 0.912)\n",
      "[8.31-9.13] The (conf: 0.962)\n",
      "[9.17-9.58] first (conf: 0.839)\n",
      "[9.80-10.28] lecture (conf: 0.893)\n",
      "[10.40-10.52] was (conf: 0.831)\n",
      "[10.60-10.80] about (conf: 0.821)\n",
      "[10.85-11.23] machine (conf: 0.794)\n",
      "[11.29-11.67] learning (conf: 0.907)\n",
      "[11.77-11.87] and (conf: 0.746)\n",
      "[11.99-12.33] AI. (conf: 0.885)\n",
      "[13.08-13.18] To (conf: 0.990)\n",
      "[13.22-13.28] be (conf: 0.316)\n",
      "[13.26-13.80] honest, (conf: 0.780)\n",
      "[14.17-14.23] I (conf: 0.963)\n",
      "[14.29-14.59] didn't (conf: 0.778)\n",
      "[14.67-15.25] understand (conf: 0.779)\n",
      "[15.29-15.62] much (conf: 0.711)\n",
      "[15.70-16.00] about (conf: 0.948)\n",
      "[16.06-16.12] it. (conf: 0.996)\n",
      "[16.14-16.93] Then (conf: 0.897)\n",
      "[16.99-17.07] it (conf: 0.410)\n",
      "[17.15-17.27] was (conf: 0.883)\n",
      "[17.31-17.57] time (conf: 0.818)\n",
      "[17.65-17.79] for (conf: 0.997)\n",
      "[17.85-18.25] lunch. (conf: 0.833)\n",
      "[18.78-18.82] I (conf: 0.953)\n",
      "[18.86-19.02] went (conf: 0.651)\n",
      "[19.04-19.08] to (conf: 0.000)\n",
      "[19.06-19.22] the (conf: 0.441)\n",
      "[19.26-19.52] store (conf: 0.858)\n",
      "[19.58-19.70] with (conf: 0.863)\n",
      "[19.76-19.89] my (conf: 0.934)\n",
      "[19.99-20.33] friends (conf: 0.791)\n",
      "[20.63-20.73] and (conf: 0.859)\n",
      "[20.85-21.11] got (conf: 0.997)\n",
      "[21.45-21.74] like (conf: 0.974)\n",
      "[22.10-22.26] a (conf: 0.840)\n",
      "[22.88-23.45] sandwich. (conf: 0.925)\n",
      "[24.21-24.37] Then (conf: 0.923)\n",
      "[24.43-24.53] we (conf: 0.753)\n",
      "[24.57-24.75] went (conf: 0.987)\n",
      "[24.84-25.02] back (conf: 0.988)\n",
      "[25.08-25.48] together. (conf: 0.959)\n",
      "[25.50-25.60] In (conf: 0.500)\n",
      "[26.06-26.40] the (conf: 0.881)\n",
      "[26.54-26.89] evening (conf: 0.839)\n",
      "[26.91-26.93] I (conf: 0.999)\n",
      "[27.29-27.51] met (conf: 0.810)\n",
      "[27.57-27.71] with (conf: 0.876)\n",
      "[27.79-27.91] my (conf: 0.897)\n",
      "[27.93-28.25] friend (conf: 0.764)\n",
      "[28.32-29.08] Preslavan (conf: 0.823)\n",
      "[29.56-29.68] and (conf: 0.806)\n",
      "[29.70-30.17] yes, (conf: 0.568)\n",
      "[30.27-30.57] so (conf: 0.970)\n",
      "[31.07-31.21] we (conf: 0.948)\n",
      "[31.25-31.42] had (conf: 0.989)\n",
      "[31.46-31.50] a (conf: 0.500)\n",
      "[31.62-31.86] fun (conf: 0.906)\n",
      "[31.92-32.02] night (conf: 0.195)\n",
      "[32.00-32.60] out (conf: 0.830)\n",
      "[32.65-33.63] drinking (conf: 0.879)\n",
      "[33.77-34.58] cocktails (conf: 0.840)\n",
      "[34.85-34.99] and (conf: 0.641)\n",
      "[35.04-35.59] eating (conf: 0.562)\n",
      "[35.72-36.95] fries. (conf: 0.745)\n",
      "\n",
      "--- Pause & Filler Stats ---\n",
      "Average pause: 0.16s\n",
      "Total silence: 12.24s\n",
      "Filler words: 3\n",
      "Filler word %: 3.61%\n",
      "['like', 'to be honest', 'so']\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
