{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0ffb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Segmentation Evaluation ---\n",
      "Mean F1: 0.6791\n",
      "Mean Pk: 0.3531\n",
      "Mean WindowDiff: 0.4671\n",
      "Documents evaluated: 278\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import f1_score\n",
    "from nltk.metrics.segmentation import pk, windowdiff\n",
    "import re\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "    return [s for s in sentences if s]\n",
    "\n",
    "def segment_starts_to_boundaries(starts, n_sentences):\n",
    "    \"\"\"\n",
    "    Convert 1-indexed sentence starts to boundary vector\n",
    "    \"\"\"\n",
    "    starts_0idx = {i - 1 for i in starts}\n",
    "    return [1 if i in starts_0idx else 0 for i in range(n_sentences)]\n",
    "\n",
    "def adaptive_threshold_segmentation(\n",
    "    embeddings,\n",
    "    percentile=30,\n",
    "    min_size=2\n",
    "):\n",
    "    sims = np.array([\n",
    "        cosine_similarity(\n",
    "            embeddings[i - 1].reshape(1, -1),\n",
    "            embeddings[i].reshape(1, -1)\n",
    "        )[0][0]\n",
    "        for i in range(1, len(embeddings))\n",
    "    ])\n",
    "\n",
    "    threshold = np.percentile(sims, percentile)\n",
    "\n",
    "    boundaries = [1]  \n",
    "    last_boundary = 0\n",
    "\n",
    "    for i in range(1, len(embeddings)):\n",
    "        sim = cosine_similarity(\n",
    "            embeddings[i - 1].reshape(1, -1),\n",
    "            embeddings[i].reshape(1, -1)\n",
    "        )[0][0]\n",
    "\n",
    "        if sim < threshold and (i - last_boundary) >= min_size:\n",
    "            boundaries.append(1)\n",
    "            last_boundary = i\n",
    "        else:\n",
    "            boundaries.append(0)\n",
    "\n",
    "    return boundaries\n",
    "\n",
    "df = pd.read_csv(\"5.cleaned_synthetic_data.csv\")\n",
    "\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "all_f1 = []\n",
    "all_pk = []\n",
    "all_wd = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    text = row[\"synthetic_text\"]\n",
    "    gt_starts = eval(row[\"ground_truth_segments\"])\n",
    "\n",
    "    sentences = split_into_sentences(text)\n",
    "    n = len(sentences)\n",
    "    if n < 2:\n",
    "        continue\n",
    "\n",
    "    embeddings = model.encode(sentences)\n",
    "\n",
    "    gold_boundaries = segment_starts_to_boundaries(gt_starts, n)\n",
    "    pred_boundaries = adaptive_threshold_segmentation(embeddings)\n",
    "\n",
    "    gold_boundaries_int = [int(b) for b in gold_boundaries]\n",
    "    pred_boundaries_int = [int(b) for b in pred_boundaries]\n",
    "\n",
    "    f1 = f1_score(gold_boundaries_int, pred_boundaries_int)\n",
    "\n",
    "    gold_str = ''.join(str(b) for b in gold_boundaries)\n",
    "    pred_str = ''.join(str(b) for b in pred_boundaries)\n",
    "\n",
    "    n_segments = max(len(gt_starts), 1)\n",
    "    avg_seg_len = max(2, int(n / n_segments))\n",
    "    avg_seg_len = min(avg_seg_len, n - 1)\n",
    "\n",
    "    pk_score = pk(gold_str, pred_str, k=avg_seg_len)\n",
    "    wd_score = windowdiff(gold_str, pred_str, k=avg_seg_len)\n",
    "\n",
    "    all_f1.append(f1)\n",
    "    all_pk.append(pk_score)\n",
    "    all_wd.append(wd_score)\n",
    "\n",
    "print(\"\\n--- Segmentation Evaluation ---\")\n",
    "print(f\"Mean F1: {np.mean(all_f1):.4f}\")\n",
    "print(f\"Mean Pk: {np.mean(all_pk):.4f}\")\n",
    "print(f\"Mean WindowDiff: {np.mean(all_wd):.4f}\")\n",
    "print(f\"Documents evaluated: {len(all_f1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae86f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Segmentation Evaluation ---\n",
      "Mean F1: 0.5102\n",
      "Mean Pk: 0.4238\n",
      "Mean WindowDiff: 0.6311\n",
      "Documents evaluated: 432\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import f1_score\n",
    "from nltk.metrics.segmentation import pk, windowdiff\n",
    "import re\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "    return [s for s in sentences if s]\n",
    "\n",
    "def adaptive_threshold_segmentation(\n",
    "    embeddings,\n",
    "    percentile=30,\n",
    "    min_size=2\n",
    "):\n",
    "    sims = np.array([\n",
    "        cosine_similarity(\n",
    "            embeddings[i - 1].reshape(1, -1),\n",
    "            embeddings[i].reshape(1, -1)\n",
    "        )[0][0]\n",
    "        for i in range(1, len(embeddings))\n",
    "    ])\n",
    "\n",
    "    threshold = np.percentile(sims, percentile)\n",
    "\n",
    "    boundaries = [1]  \n",
    "    last_boundary = 0\n",
    "\n",
    "    for i in range(1, len(embeddings)):\n",
    "        sim = cosine_similarity(\n",
    "            embeddings[i - 1].reshape(1, -1),\n",
    "            embeddings[i].reshape(1, -1)\n",
    "        )[0][0]\n",
    "\n",
    "        if sim < threshold and (i - last_boundary) >= min_size:\n",
    "            boundaries.append(1)\n",
    "            last_boundary = i\n",
    "        else:\n",
    "            boundaries.append(0)\n",
    "\n",
    "    return boundaries\n",
    "\n",
    "df = pd.read_csv(\"journal_diary_with_tags_fixed_segments.csv\")\n",
    "\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "all_f1 = []\n",
    "all_pk = []\n",
    "all_wd = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    text = row[\"body\"]\n",
    "    segments_str = row[\"segments\"]\n",
    "    \n",
    "    sentences = split_into_sentences(text)\n",
    "    n = len(sentences)\n",
    "    if n < 2:\n",
    "        continue\n",
    "\n",
    "    segments_str = segments_str.strip()\n",
    "    if segments_str.startswith('['):\n",
    "        gold_boundaries = eval(segments_str)\n",
    "    else:\n",
    "        gold_boundaries = [int(x.strip()) for x in segments_str.split(',')]\n",
    "    \n",
    "    if len(gold_boundaries) != n:\n",
    "        print(f\"Skipping row: gold boundaries ({len(gold_boundaries)}) != sentences ({n})\")\n",
    "        continue\n",
    "\n",
    "    embeddings = model.encode(sentences)\n",
    "    pred_boundaries = adaptive_threshold_segmentation(embeddings)\n",
    "\n",
    "    gold_boundaries_int = [int(b) for b in gold_boundaries]\n",
    "    pred_boundaries_int = [int(b) for b in pred_boundaries]\n",
    "\n",
    "    f1 = f1_score(gold_boundaries_int, pred_boundaries_int)\n",
    "\n",
    "    gold_str = ''.join(str(b) for b in gold_boundaries)\n",
    "    pred_str = ''.join(str(b) for b in pred_boundaries)\n",
    "\n",
    "    n_segments = max(sum(gold_boundaries), 1)\n",
    "    avg_seg_len = max(2, int(n / n_segments))\n",
    "    avg_seg_len = min(avg_seg_len, n - 1)\n",
    "\n",
    "    pk_score = pk(gold_str, pred_str, k=avg_seg_len)\n",
    "    wd_score = windowdiff(gold_str, pred_str, k=avg_seg_len)\n",
    "\n",
    "    all_f1.append(f1)\n",
    "    all_pk.append(pk_score)\n",
    "    all_wd.append(wd_score)\n",
    "\n",
    "print(\"\\n--- Segmentation Evaluation ---\")\n",
    "print(f\"Mean F1: {np.mean(all_f1):.4f}\")\n",
    "print(f\"Mean Pk: {np.mean(all_pk):.4f}\")\n",
    "print(f\"Mean WindowDiff: {np.mean(all_wd):.4f}\")\n",
    "print(f\"Documents evaluated: {len(all_f1)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
