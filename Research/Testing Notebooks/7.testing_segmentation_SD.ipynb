{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9041fdc",
   "metadata": {},
   "source": [
    "# Testing explored segmentation methods on synthetic data\n",
    "- Adaptive threshold segmentation\n",
    "- TextTiling\n",
    "- Sequential thresholding\n",
    "- Adaptive sequential thresholding\n",
    "- BATS\n",
    "\n",
    "This subject is still not finished - the idea for better data generation and re-done testing is still to de implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9a0e361",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo X1 Carbon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import ast\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0689736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_threshold_segmentation(embeddings, method=\"percentile\", min_size=2, std_factor=1.0, percentile=30):\n",
    "    \"\"\"Segment text adaptively based on cosine similarity of consecutive sentence embeddings.\"\"\"\n",
    "    num_sentences = embeddings.shape[0]\n",
    "    sims = []\n",
    "\n",
    "    for i in range(1, num_sentences):\n",
    "        sim = cosine_similarity(\n",
    "            embeddings[i-1].reshape(1,-1),\n",
    "            embeddings[i].reshape(1,-1)\n",
    "        )[0][0]\n",
    "        sims.append(sim)\n",
    "    sims = np.array(sims)\n",
    "\n",
    "    if method == \"std\":\n",
    "        threshold = sims.mean() - std_factor * sims.std()\n",
    "    elif method == \"percentile\":\n",
    "        threshold = np.percentile(sims, percentile)\n",
    "    else:\n",
    "        raise ValueError(\"method must be 'std' or 'percentile'\")\n",
    "\n",
    "    pred_segments = [0]\n",
    "    current_segment = 0\n",
    "    last_boundary = 0\n",
    "\n",
    "    for i in range(1, num_sentences):\n",
    "        sim = sims[i-1]\n",
    "        if sim < threshold and (i - last_boundary) >= min_size:\n",
    "            current_segment += 1\n",
    "            last_boundary = i\n",
    "        pred_segments.append(current_segment)\n",
    "\n",
    "    return pred_segments, threshold\n",
    "\n",
    "\n",
    "# === 2. SIMPLE HELPERS ===\n",
    "def split_sentences(text):\n",
    "    \"\"\"Basic rule-based sentence splitter.\"\"\"\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "    return [s for s in sentences if s]\n",
    "\n",
    "def boundaries_from_segments(segment_indices, num_sentences):\n",
    "    \"\"\"Convert list of segment start indices into 0/1 boundary labels.\"\"\"\n",
    "    boundaries = [0] * (num_sentences - 1)\n",
    "    for idx in segment_indices:\n",
    "        if 0 < idx < num_sentences:\n",
    "            boundaries[idx - 1] = 1\n",
    "    return boundaries\n",
    "\n",
    "def boundary_f1(pred, gold):\n",
    "    p, r, f, _ = precision_recall_fscore_support(gold, pred, average=\"binary\", zero_division=0)\n",
    "    return p, r, f\n",
    "\n",
    "def pk_metric(pred, gold, k=None):\n",
    "    n = len(pred) + 1\n",
    "    if k is None:\n",
    "        k = int(round(n / 2.0))\n",
    "    errors = 0\n",
    "    total = 0\n",
    "    for i in range(0, n - k):\n",
    "        a = sum(gold[i:i+k-1]) > 0\n",
    "        b = sum(pred[i:i+k-1]) > 0\n",
    "        errors += (a != b)\n",
    "        total += 1\n",
    "    return errors / total\n",
    "\n",
    "def windowdiff(pred, gold, k=None):\n",
    "    n = len(pred) + 1\n",
    "    if k is None:\n",
    "        k = int(round(n / 2.0))\n",
    "    errors = 0\n",
    "    total = 0\n",
    "    for i in range(0, n - k):\n",
    "        a = sum(gold[i:i+k-1])\n",
    "        b = sum(pred[i:i+k-1])\n",
    "        errors += (a != b)\n",
    "        total += 1\n",
    "    return errors / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97a9b15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"5.cleaned_synthetic_data.csv\")\n",
    "df[\"ground_truth_segments\"] = df[\"ground_truth_segments\"].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd06268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "def evaluate_dataset(df, percentile=30, min_size=2, method=\"percentile\"):\n",
    "    metrics = []\n",
    "    for _, row in df.iterrows():\n",
    "        sentences = split_sentences(row[\"synthetic_text\"])\n",
    "        if len(sentences) < 3:\n",
    "            continue\n",
    "\n",
    "        embeddings = model.encode(sentences, batch_size=8, show_progress_bar=False)\n",
    "        pred_segments, threshold = adaptive_threshold_segmentation(\n",
    "            embeddings, method=method, min_size=min_size, percentile=percentile\n",
    "        )\n",
    "\n",
    "        pred_boundaries = [1 if pred_segments[i] != pred_segments[i-1] else 0 for i in range(1, len(pred_segments))]\n",
    "        gt_indices = [idx for idx in row[\"ground_truth_segments\"] if idx != 1]\n",
    "        gold_boundaries = boundaries_from_segments(gt_indices, len(sentences))\n",
    "\n",
    "        pred_boundaries = [1 if pred_segments[i] != pred_segments[i-1] else 0 for i in range(1, len(pred_segments))]\n",
    "        \n",
    "        p, r, f = boundary_f1(pred_boundaries, gold_boundaries)\n",
    "        pk = pk_metric(pred_boundaries, gold_boundaries)\n",
    "        wd = windowdiff(pred_boundaries, gold_boundaries)\n",
    "        metrics.append((p, r, f, pk, wd))\n",
    "\n",
    "    arr = np.array(metrics)\n",
    "    return {\n",
    "        \"Precision\": arr[:,0].mean(),\n",
    "        \"Recall\": arr[:,1].mean(),\n",
    "        \"F1\": arr[:,2].mean(),\n",
    "        \"Pk\": arr[:,3].mean(),\n",
    "        \"WindowDiff\": arr[:,4].mean(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae19394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Percentile = 20 ===\n",
      "DEV   -> F1: 0.277,  Pk: 0.246,  WD: 0.250\n",
      "\n",
      "=== Percentile = 30 ===\n",
      "DEV   -> F1: 0.275,  Pk: 0.249,  WD: 0.251\n",
      "\n",
      "=== Percentile = 40 ===\n",
      "DEV   -> F1: 0.311,  Pk: 0.252,  WD: 0.255\n",
      "\n",
      "=== Percentile = 50 ===\n",
      "DEV   -> F1: 0.311,  Pk: 0.252,  WD: 0.255\n",
      "\n",
      "=== Percentile = 60 ===\n",
      "DEV   -> F1: 0.251,  Pk: 0.341,  WD: 0.345\n"
     ]
    }
   ],
   "source": [
    "for percentile in [20, 30, 40, 50, 60]:\n",
    "    results = evaluate_dataset(df, percentile=percentile)\n",
    "   \n",
    "\n",
    "    print(f\"\\n=== Percentile = {percentile} ===\")\n",
    "    print(f\"DEV   -> F1: {results['F1']:.3f},  Pk: {results['Pk']:.3f},  WD: {results['WindowDiff']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1380f8e5",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd6abba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== window_size=2 | threshold=0.75 ===\n",
      "F1: 0.424,  Pk: 0.252,  WD: 0.256\n",
      "\n",
      "=== window_size=2 | threshold=0.90 ===\n",
      "F1: 0.541,  Pk: 0.360,  WD: 0.364\n",
      "\n",
      "=== window_size=2 | threshold=0.95 ===\n",
      "F1: 0.543,  Pk: 0.360,  WD: 0.364\n",
      "\n",
      "=== window_size=2 | threshold=0.99 ===\n",
      "F1: 0.543,  Pk: 0.360,  WD: 0.364\n",
      "\n",
      "=== window_size=3 | threshold=0.75 ===\n",
      "F1: 0.004,  Pk: 0.149,  WD: 0.149\n",
      "\n",
      "=== window_size=3 | threshold=0.90 ===\n",
      "F1: 0.675,  Pk: 0.045,  WD: 0.045\n",
      "\n",
      "=== window_size=3 | threshold=0.95 ===\n",
      "F1: 0.705,  Pk: 0.040,  WD: 0.040\n",
      "\n",
      "=== window_size=3 | threshold=0.99 ===\n",
      "F1: 0.705,  Pk: 0.040,  WD: 0.040\n"
     ]
    }
   ],
   "source": [
    "def embedding_text_tiling(embeddings, window_size=2, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Simple TextTiling variant using embedding similarity between adjacent windows.\n",
    "    Returns boundary indices (sentence indices where a topic boundary is predicted).\n",
    "    \"\"\"\n",
    "    num_sentences = embeddings.shape[0]\n",
    "    boundaries = []\n",
    "\n",
    "    for i in range(num_sentences - window_size):\n",
    "        block1 = embeddings[i:i+window_size].mean(axis=0)\n",
    "        block2 = embeddings[i+1:i+1+window_size].mean(axis=0)\n",
    "        sim = cosine_similarity(block1.reshape(1, -1), block2.reshape(1, -1))[0][0]\n",
    "        if sim < threshold:\n",
    "            boundaries.append(i + window_size - 1)\n",
    "    return boundaries\n",
    "\n",
    "\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "def evaluate_texttiling(df, window_sizes=[2,3], thresholds=[0.75,0.9,0.95,0.99]):\n",
    "    \"\"\"\n",
    "    Evaluate embedding-based TextTiling on a dataset of journaling entries.\n",
    "    Returns average Precision, Recall, F1, Pk, and WindowDiff for each parameter combo.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for window_size in window_sizes:\n",
    "        for threshold in thresholds:\n",
    "            metrics = []\n",
    "\n",
    "            for _, row in df.iterrows():\n",
    "                sentences = split_sentences(row[\"synthetic_text\"])\n",
    "                if len(sentences) < window_size + 1:\n",
    "                    continue\n",
    "\n",
    "                embeddings = model.encode(sentences, batch_size=8, show_progress_bar=False)\n",
    "\n",
    "                pred_boundary_indices = embedding_text_tiling(\n",
    "                    embeddings,\n",
    "                    window_size=window_size,\n",
    "                    threshold=threshold\n",
    "                )\n",
    "\n",
    "                pred_boundaries = [1 if i in pred_boundary_indices else 0 for i in range(len(sentences) - 1)]\n",
    "\n",
    "                gt_indices = [idx for idx in row[\"ground_truth_segments\"] if idx != 1]\n",
    "                gold_boundaries = boundaries_from_segments(gt_indices, len(sentences))\n",
    "\n",
    "                p, r, f = boundary_f1(pred_boundaries, gold_boundaries)\n",
    "                pk = pk_metric(pred_boundaries, gold_boundaries)\n",
    "                wd = windowdiff(pred_boundaries, gold_boundaries)\n",
    "\n",
    "                metrics.append((p, r, f, pk, wd))\n",
    "\n",
    "            if not metrics:\n",
    "                continue\n",
    "\n",
    "            arr = np.array(metrics)\n",
    "            results.append({\n",
    "                \"window_size\": window_size,\n",
    "                \"threshold\": threshold,\n",
    "                \"Precision\": arr[:,0].mean(),\n",
    "                \"Recall\": arr[:,1].mean(),\n",
    "                \"F1\": arr[:,2].mean(),\n",
    "                \"Pk\": arr[:,3].mean(),\n",
    "                \"WindowDiff\": arr[:,4].mean(),\n",
    "            })\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "results = evaluate_texttiling(df)\n",
    "\n",
    "for res in results:\n",
    "    print(f\"\\n=== window_size={res['window_size']} | threshold={res['threshold']:.2f} ===\")\n",
    "    print(f\"F1: {res['F1']:.3f},  Pk: {res['Pk']:.3f},  WD: {res['WindowDiff']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df79df77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== threshold=0.20 ===\n",
      "F1: 0.128,  Pk: 0.248,  WD: 0.251\n",
      "\n",
      "=== threshold=0.50 ===\n",
      "F1: 0.430,  Pk: 0.802,  WD: 0.805\n",
      "\n",
      "=== threshold=0.80 ===\n",
      "F1: 0.416,  Pk: 0.869,  WD: 0.873\n"
     ]
    }
   ],
   "source": [
    "def sequential_thresholding(embeddings, threshold=0.75):\n",
    "    num_sentences = embeddings.shape[0]\n",
    "    pred_segments = [0]  \n",
    "    current_segment = 0\n",
    "\n",
    "    for i in range(1, num_sentences):\n",
    "        sim = cosine_similarity(\n",
    "            embeddings[i-1].reshape(1,-1), embeddings[i].reshape(1,-1)\n",
    "        )[0][0]\n",
    "        if sim < threshold:\n",
    "            current_segment += 1\n",
    "        pred_segments.append(current_segment)\n",
    "\n",
    "    return pred_segments\n",
    "\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "def evaluate_sequential_thresholding(df, thresholds=[0.2,0.5,0.8]):\n",
    "    \"\"\"\n",
    "    Evaluate the sequential_thresholding segmentation method over a threshold grid.\n",
    "    Returns metrics for each threshold.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        metrics = []\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            sentences = split_sentences(row[\"synthetic_text\"])\n",
    "            if len(sentences) < 2:\n",
    "                continue  \n",
    "\n",
    "            embeddings = model.encode(sentences, batch_size=8, show_progress_bar=False)\n",
    "\n",
    "            pred_segments = sequential_thresholding(embeddings, threshold=threshold)\n",
    "\n",
    "            pred_boundaries = [1 if pred_segments[i] != pred_segments[i-1] else 0 for i in range(1, len(pred_segments))]\n",
    "\n",
    "            gt_indices = [idx for idx in row[\"ground_truth_segments\"] if idx != 1]\n",
    "            gold_boundaries = boundaries_from_segments(gt_indices, len(sentences))\n",
    "\n",
    "            p, r, f = boundary_f1(pred_boundaries, gold_boundaries)\n",
    "            pk = pk_metric(pred_boundaries, gold_boundaries)\n",
    "            wd = windowdiff(pred_boundaries, gold_boundaries)\n",
    "\n",
    "            metrics.append((p, r, f, pk, wd))\n",
    "\n",
    "        if not metrics:\n",
    "            continue\n",
    "\n",
    "        arr = np.array(metrics)\n",
    "        results.append({\n",
    "            \"threshold\": threshold,\n",
    "            \"Precision\": arr[:,0].mean(),\n",
    "            \"Recall\": arr[:,1].mean(),\n",
    "            \"F1\": arr[:,2].mean(),\n",
    "            \"Pk\": arr[:,3].mean(),\n",
    "            \"WindowDiff\": arr[:,4].mean(),\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "results = evaluate_sequential_thresholding(df)\n",
    "\n",
    "for res in results:\n",
    "    print(f\"\\n=== threshold={res['threshold']:.2f} ===\")\n",
    "    print(f\"F1: {res['F1']:.3f},  Pk: {res['Pk']:.3f},  WD: {res['WindowDiff']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f87c09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== threshold=0.40 ===\n",
      "F1: 0.409,  Pk: 0.746,  WD: 0.749\n",
      "\n",
      "=== threshold=0.60 ===\n",
      "F1: 0.420,  Pk: 0.851,  WD: 0.854\n",
      "\n",
      "=== threshold=0.80 ===\n",
      "F1: 0.416,  Pk: 0.869,  WD: 0.873\n"
     ]
    }
   ],
   "source": [
    "def adaptive_sequential_thresholding(embeddings, threshold):\n",
    "    pred_segments = [0]\n",
    "    current_segment = 0\n",
    "    segment_vectors = [embeddings[0]]  \n",
    "\n",
    "    for i in range(1, len(embeddings)):\n",
    "        centroid = np.mean(segment_vectors, axis=0)\n",
    "        sim = cosine_similarity(embeddings[i].reshape(1, -1), centroid.reshape(1, -1))[0][0]\n",
    "        if sim < threshold:\n",
    "            current_segment += 1\n",
    "            segment_vectors = [embeddings[i]] \n",
    "        else:\n",
    "            segment_vectors.append(embeddings[i])\n",
    "        pred_segments.append(current_segment)\n",
    "\n",
    "    return pred_segments\n",
    "\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "def evaluate_adaptive_sequential_thresholding(df, thresholds=[0.4,0.6,0.8]):\n",
    "    \"\"\"\n",
    "    Evaluate adaptive_sequential_thresholding over a range of thresholds.\n",
    "    Returns average metrics for each threshold.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        metrics = []\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            sentences = split_sentences(row[\"synthetic_text\"])\n",
    "            if len(sentences) < 2:\n",
    "                continue \n",
    "\n",
    "            embeddings = model.encode(sentences, batch_size=8, show_progress_bar=False)\n",
    "\n",
    "            pred_segments = adaptive_sequential_thresholding(embeddings, threshold=threshold)\n",
    "\n",
    "            pred_boundaries = [1 if pred_segments[i] != pred_segments[i-1] else 0 for i in range(1, len(pred_segments))]\n",
    "\n",
    "            gt_indices = [idx for idx in row[\"ground_truth_segments\"] if idx != 1]\n",
    "            gold_boundaries = boundaries_from_segments(gt_indices, len(sentences))\n",
    "\n",
    "            p, r, f = boundary_f1(pred_boundaries, gold_boundaries)\n",
    "            pk = pk_metric(pred_boundaries, gold_boundaries)\n",
    "            wd = windowdiff(pred_boundaries, gold_boundaries)\n",
    "\n",
    "            metrics.append((p, r, f, pk, wd))\n",
    "\n",
    "        if not metrics:\n",
    "            continue\n",
    "\n",
    "        arr = np.array(metrics)\n",
    "        results.append({\n",
    "            \"threshold\": threshold,\n",
    "            \"Precision\": arr[:,0].mean(),\n",
    "            \"Recall\": arr[:,1].mean(),\n",
    "            \"F1\": arr[:,2].mean(),\n",
    "            \"Pk\": arr[:,3].mean(),\n",
    "            \"WindowDiff\": arr[:,4].mean(),\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "results = evaluate_adaptive_sequential_thresholding(df)\n",
    "\n",
    "for res in results:\n",
    "    print(f\"\\n=== threshold={res['threshold']:.2f} ===\")\n",
    "    print(f\"F1: {res['F1']:.3f},  Pk: {res['Pk']:.3f},  WD: {res['WindowDiff']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93f3ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo X1 Carbon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_bicluster.py:31: RuntimeWarning: divide by zero encountered in divide\n",
      "  row_diag = np.asarray(1.0 / np.sqrt(X.sum(axis=1))).squeeze()\n",
      "c:\\Users\\Lenovo X1 Carbon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_bicluster.py:41: RuntimeWarning: invalid value encountered in multiply\n",
      "  an = row_diag[:, np.newaxis] * X * col_diag\n",
      "c:\\Users\\Lenovo X1 Carbon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_bicluster.py:31: RuntimeWarning: divide by zero encountered in divide\n",
      "  row_diag = np.asarray(1.0 / np.sqrt(X.sum(axis=1))).squeeze()\n",
      "c:\\Users\\Lenovo X1 Carbon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_bicluster.py:41: RuntimeWarning: invalid value encountered in multiply\n",
      "  an = row_diag[:, np.newaxis] * X * col_diag\n",
      "c:\\Users\\Lenovo X1 Carbon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_bicluster.py:31: RuntimeWarning: divide by zero encountered in divide\n",
      "  row_diag = np.asarray(1.0 / np.sqrt(X.sum(axis=1))).squeeze()\n",
      "c:\\Users\\Lenovo X1 Carbon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_bicluster.py:41: RuntimeWarning: invalid value encountered in multiply\n",
      "  an = row_diag[:, np.newaxis] * X * col_diag\n",
      "c:\\Users\\Lenovo X1 Carbon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_bicluster.py:31: RuntimeWarning: divide by zero encountered in divide\n",
      "  row_diag = np.asarray(1.0 / np.sqrt(X.sum(axis=1))).squeeze()\n",
      "c:\\Users\\Lenovo X1 Carbon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_bicluster.py:41: RuntimeWarning: invalid value encountered in multiply\n",
      "  an = row_diag[:, np.newaxis] * X * col_diag\n",
      "c:\\Users\\Lenovo X1 Carbon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_bicluster.py:31: RuntimeWarning: divide by zero encountered in divide\n",
      "  row_diag = np.asarray(1.0 / np.sqrt(X.sum(axis=1))).squeeze()\n",
      "c:\\Users\\Lenovo X1 Carbon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_bicluster.py:41: RuntimeWarning: invalid value encountered in multiply\n",
      "  an = row_diag[:, np.newaxis] * X * col_diag\n",
      "c:\\Users\\Lenovo X1 Carbon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_bicluster.py:31: RuntimeWarning: divide by zero encountered in divide\n",
      "  row_diag = np.asarray(1.0 / np.sqrt(X.sum(axis=1))).squeeze()\n",
      "c:\\Users\\Lenovo X1 Carbon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_bicluster.py:41: RuntimeWarning: invalid value encountered in multiply\n",
      "  an = row_diag[:, np.newaxis] * X * col_diag\n",
      "c:\\Users\\Lenovo X1 Carbon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_bicluster.py:31: RuntimeWarning: divide by zero encountered in divide\n",
      "  row_diag = np.asarray(1.0 / np.sqrt(X.sum(axis=1))).squeeze()\n",
      "c:\\Users\\Lenovo X1 Carbon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_bicluster.py:41: RuntimeWarning: invalid value encountered in multiply\n",
      "  an = row_diag[:, np.newaxis] * X * col_diag\n",
      "c:\\Users\\Lenovo X1 Carbon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_bicluster.py:31: RuntimeWarning: divide by zero encountered in divide\n",
      "  row_diag = np.asarray(1.0 / np.sqrt(X.sum(axis=1))).squeeze()\n",
      "c:\\Users\\Lenovo X1 Carbon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_bicluster.py:41: RuntimeWarning: invalid value encountered in multiply\n",
      "  an = row_diag[:, np.newaxis] * X * col_diag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_topics=2, boost_factor=1.0\n",
      "F1: 0.238,  Pk: 0.598,  WD: 0.599\n",
      "\n",
      "n_topics=2, boost_factor=1.5\n",
      "F1: 0.305,  Pk: 0.481,  WD: 0.484\n",
      "\n",
      "n_topics=2, boost_factor=2.0\n",
      "F1: 0.251,  Pk: 0.588,  WD: 0.592\n",
      "\n",
      "n_topics=2, boost_factor=2.5\n",
      "F1: 0.220,  Pk: 0.596,  WD: 0.599\n",
      "\n",
      "n_topics=3, boost_factor=1.0\n",
      "F1: 0.350,  Pk: 0.791,  WD: 0.795\n",
      "\n",
      "n_topics=3, boost_factor=1.5\n",
      "F1: 0.391,  Pk: 0.746,  WD: 0.750\n",
      "\n",
      "n_topics=3, boost_factor=2.0\n",
      "F1: 0.402,  Pk: 0.738,  WD: 0.742\n",
      "\n",
      "n_topics=3, boost_factor=2.5\n",
      "F1: 0.352,  Pk: 0.809,  WD: 0.812\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import SpectralCoclustering\n",
    "\n",
    "def bats_segmentation(sentences, n_topics=2, noise_thresh=0.0005, boost_factor=2.0):\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=5000)\n",
    "    M = vectorizer.fit_transform(sentences).toarray()  \n",
    "    words = vectorizer.get_feature_names_out()\n",
    "\n",
    "    col_vars = np.var(M, axis=0)\n",
    "    keep_mask = col_vars > noise_thresh\n",
    "    M = M[:, keep_mask]\n",
    "    col_vars = col_vars[keep_mask]\n",
    "    words = [w for w, k in zip(words, keep_mask) if k]\n",
    "\n",
    "    if len(words) == 0:\n",
    "        raise ValueError(\"No informative words left after pruning. Try lowering noise_thresh.\")\n",
    "\n",
    "    var_norm = col_vars / (col_vars.max() + 1e-9)\n",
    "    boost = 1 + (boost_factor - 1) * var_norm\n",
    "    M = M * boost[np.newaxis, :]\n",
    "\n",
    "    model = SpectralCoclustering(n_clusters=n_topics, random_state=42)\n",
    "    model.fit(M)\n",
    "    sent_labels = model.row_labels_\n",
    "\n",
    "    boundaries = []\n",
    "    for i in range(1, len(sent_labels)):\n",
    "        if sent_labels[i] != sent_labels[i-1]:\n",
    "            boundaries.append(i-1)\n",
    "\n",
    "    segments = [0] * len(sentences)\n",
    "    current = 0\n",
    "    for i in range(len(sentences)):\n",
    "        segments[i] = current\n",
    "        if i in boundaries:\n",
    "            current += 1\n",
    "\n",
    "    return segments, boundaries, sent_labels\n",
    "\n",
    "def evaluate_bats_grid(df, n_topics_list=[2,3], boost_factors=[1.0,1.5,2.0,2.5]):\n",
    "    results = []\n",
    "\n",
    "    for n_topics in n_topics_list:\n",
    "        for boost in boost_factors:\n",
    "            metrics = []\n",
    "\n",
    "            for _, row in df.iterrows():\n",
    "                sentences = split_sentences(row[\"synthetic_text\"])\n",
    "                if len(sentences) < 2:\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    pred_segments, boundaries, _ = bats_segmentation(\n",
    "                        sentences, n_topics=n_topics, boost_factor=boost\n",
    "                    )\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "                # Convert predicted segments to 0/1 boundaries\n",
    "                pred_boundaries = [1 if pred_segments[i] != pred_segments[i-1] else 0 for i in range(1, len(pred_segments))]\n",
    "\n",
    "                # Ground truth\n",
    "                gt_indices = [idx for idx in row[\"ground_truth_segments\"] if idx != 1]\n",
    "                gold_boundaries = boundaries_from_segments(gt_indices, len(sentences))\n",
    "\n",
    "                # Compute metrics\n",
    "                p, r, f = boundary_f1(pred_boundaries, gold_boundaries)\n",
    "                pk = pk_metric(pred_boundaries, gold_boundaries)\n",
    "                wd = windowdiff(pred_boundaries, gold_boundaries)\n",
    "\n",
    "                metrics.append((p, r, f, pk, wd))\n",
    "\n",
    "            if not metrics:\n",
    "                continue\n",
    "\n",
    "            arr = np.array(metrics)\n",
    "            results.append({\n",
    "                \"n_topics\": n_topics,\n",
    "                \"boost_factor\": boost,\n",
    "                \"Precision\": arr[:,0].mean(),\n",
    "                \"Recall\": arr[:,1].mean(),\n",
    "                \"F1\": arr[:,2].mean(),\n",
    "                \"Pk\": arr[:,3].mean(),\n",
    "                \"WindowDiff\": arr[:,4].mean(),\n",
    "            })\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "grid_results = evaluate_bats_grid(df)\n",
    "\n",
    "for res in grid_results:\n",
    "    print(f\"\\nn_topics={res['n_topics']}, boost_factor={res['boost_factor']}\")\n",
    "    print(f\"F1: {res['F1']:.3f},  Pk: {res['Pk']:.3f},  WD: {res['WindowDiff']:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
