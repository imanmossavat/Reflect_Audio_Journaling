{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1debb647",
   "metadata": {},
   "source": [
    "# Transcription enhancement\n",
    "This code processes an audio file by first transcribing it with OpenAI’s Whisper model and then refining the alignment and timing with WhisperX. Whisper is used initially because WhisperX, while better at precise word-level alignment, does not support prompts — short pieces of text that help the model recognize context-specific or domain-related vocabulary. In this case, the prompt includes terms like “Fontys University, Eindhoven, Netherlands,” which guide the transcription model to better capture specialized names and phrases that might otherwise be misheard. After generating the transcript, the code uses WhisperX to synchronize each word with its exact timing, analyze confidence scores, detect pauses and filler words, and calculate accuracy metrics such as word and character error rates. The result is a detailed, context-aware transcription with linguistic and performance insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1e7bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with Whisper (with prompt)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo X1 Carbon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected language: en\n",
      "Loading WhisperX alignment model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo X1 Carbon\\AppData\\Local\\Temp\\ipykernel_11436\\3823936853.py:45: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio, sr = librosa.load(audio_file, sr=16000, mono=True)\n",
      "c:\\Users\\Lenovo X1 Carbon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded audio sr=16000, duration=35.65s\n",
      "Aligning Whisper transcript with WhisperX...\n",
      "\n",
      "--- Word-Level Transcription with Confidence Scores ---\n",
      "[0.00 - 1.21] Today (conf: 0.707)\n",
      "[1.23 - 1.25] I (conf: 0.999)\n",
      "[1.29 - 1.97] woke (conf: 0.724)\n",
      "[2.15 - 2.25] up, (conf: 0.918)\n",
      "[2.56 - 2.86] brushed (conf: 0.857)\n",
      "[2.94 - 3.08] my (conf: 0.996)\n",
      "[3.18 - 3.54] teeth, (conf: 0.713)\n",
      "[4.14 - 4.33] got (conf: 0.989)\n",
      "[4.41 - 4.77] dressed (conf: 0.919)\n",
      "[4.91 - 4.99] up (conf: 0.990)\n",
      "[5.17 - 5.29] and (conf: 0.779)\n",
      "[5.39 - 5.59] went (conf: 0.962)\n",
      "[5.77 - 5.91] out. (conf: 0.999)\n",
      "[6.54 - 6.60] I (conf: 0.995)\n",
      "[6.66 - 6.94] study (conf: 0.599)\n",
      "[6.96 - 7.00] at (conf: 0.275)\n",
      "[6.98 - 7.48] Fontys (conf: 0.859)\n",
      "[7.54 - 8.29] University. (conf: 0.912)\n",
      "[8.31 - 9.13] The (conf: 0.962)\n",
      "[9.17 - 9.58] first (conf: 0.839)\n",
      "[9.80 - 10.28] lecture (conf: 0.893)\n",
      "[10.40 - 10.52] was (conf: 0.831)\n",
      "[10.60 - 10.80] about (conf: 0.821)\n",
      "[10.85 - 11.23] machine (conf: 0.794)\n",
      "[11.29 - 11.67] learning (conf: 0.907)\n",
      "[11.77 - 11.87] and (conf: 0.746)\n",
      "[11.99 - 12.33] AI. (conf: 0.885)\n",
      "[13.08 - 13.18] To (conf: 0.990)\n",
      "[13.22 - 13.28] be (conf: 0.316)\n",
      "[13.26 - 13.80] honest, (conf: 0.780)\n",
      "[14.17 - 14.23] I (conf: 0.963)\n",
      "[14.29 - 14.59] didn't (conf: 0.778)\n",
      "[14.67 - 15.25] understand (conf: 0.779)\n",
      "[15.29 - 15.62] much (conf: 0.711)\n",
      "[15.70 - 16.00] about (conf: 0.948)\n",
      "[16.06 - 16.12] it. (conf: 0.996)\n",
      "[16.14 - 16.93] Then (conf: 0.897)\n",
      "[16.99 - 17.07] it (conf: 0.410)\n",
      "[17.15 - 17.27] was (conf: 0.883)\n",
      "[17.31 - 17.57] time (conf: 0.818)\n",
      "[17.65 - 17.79] for (conf: 0.997)\n",
      "[17.85 - 18.25] lunch. (conf: 0.833)\n",
      "[18.78 - 18.82] I (conf: 0.953)\n",
      "[18.86 - 19.02] went (conf: 0.651)\n",
      "[19.04 - 19.08] to (conf: 0.000)\n",
      "[19.06 - 19.22] the (conf: 0.441)\n",
      "[19.26 - 19.52] store (conf: 0.858)\n",
      "[19.58 - 19.70] with (conf: 0.863)\n",
      "[19.76 - 19.89] my (conf: 0.934)\n",
      "[19.99 - 20.33] friends (conf: 0.791)\n",
      "[20.63 - 20.73] and (conf: 0.859)\n",
      "[20.85 - 21.11] got (conf: 0.997)\n",
      "[21.45 - 21.74] like (conf: 0.974)\n",
      "[22.10 - 22.26] a (conf: 0.840)\n",
      "[22.88 - 23.45] sandwich. (conf: 0.925)\n",
      "[24.21 - 24.37] Then (conf: 0.923)\n",
      "[24.43 - 24.53] we (conf: 0.753)\n",
      "[24.57 - 24.75] went (conf: 0.987)\n",
      "[24.84 - 25.02] back (conf: 0.988)\n",
      "[25.08 - 25.48] together. (conf: 0.959)\n",
      "[25.50 - 25.60] In (conf: 0.500)\n",
      "[26.06 - 26.40] the (conf: 0.881)\n",
      "[26.54 - 26.89] evening (conf: 0.839)\n",
      "[26.91 - 26.93] I (conf: 0.999)\n",
      "[27.29 - 27.51] met (conf: 0.810)\n",
      "[27.57 - 27.71] with (conf: 0.876)\n",
      "[27.79 - 27.91] my (conf: 0.897)\n",
      "[27.93 - 28.25] friend (conf: 0.764)\n",
      "[28.32 - 29.08] Preslavan (conf: 0.823)\n",
      "[29.56 - 29.68] and (conf: 0.806)\n",
      "[29.70 - 30.17] yes, (conf: 0.568)\n",
      "[30.27 - 30.57] so (conf: 0.970)\n",
      "[31.07 - 31.21] we (conf: 0.948)\n",
      "[31.25 - 31.42] had (conf: 0.989)\n",
      "[31.46 - 31.50] a (conf: 0.500)\n",
      "[31.62 - 31.86] fun (conf: 0.906)\n",
      "[31.92 - 32.02] night (conf: 0.195)\n",
      "[32.00 - 32.60] out (conf: 0.830)\n",
      "[32.65 - 33.63] drinking (conf: 0.879)\n",
      "[33.77 - 34.58] cocktails (conf: 0.840)\n",
      "[34.85 - 34.99] and (conf: 0.641)\n",
      "[35.04 - 35.59] eating (conf: 0.562)\n",
      "[35.72 - 36.95] fries. (conf: 0.745)\n",
      "\n",
      "--- Confidence Statistics ---\n",
      "Mean: 0.812, Median: 0.859, Std: 0.195\n",
      "Min: 0.000, Max: 0.999\n",
      "Low-confidence words (< 0.7): 13\n",
      "\n",
      "Using English filler word list.\n",
      "\n",
      "--- Pause & Filler Analysis ---\n",
      "Average pause between words: 0.16s\n",
      "Total silence duration: 12.24s\n",
      "Filler word count: 1\n",
      "Filler word percentage: 1.20%\n",
      "\n",
      "--- Evaluation ---\n",
      "WER: 0.071\n",
      "CER: 0.021\n",
      "CHRF: 93.858\n",
      "RTF: 1.480\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import whisperx\n",
    "import time\n",
    "import jiwer\n",
    "import sacrebleu\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "audio_file = \"TestAudio.m4a\"\n",
    "device = \"cpu\"\n",
    "\n",
    "prompt_text = (\n",
    "    \"Fontys University, Eindhoven, Netherlands\"\n",
    ")\n",
    "\n",
    "reference = \"\"\"Today I woke up, brushed my teeth, got dressed up and went out. I study at Fontys university. The first lecture was about machine learning and AI. To be honest, I didn’t understand much about it. Then it was time for lunch. I went to the store with my friends and got like um a sandwich. Then we went back together. In the evening I met with my friend Preslava and yeah so we had a fun night out, drinking cocktails and eating fries.\"\"\"\n",
    "\n",
    "print(\"Transcribing with Whisper (with prompt)...\")\n",
    "model_whisper = whisper.load_model(\"medium\", device=device)\n",
    "\n",
    "start_time = time.time()\n",
    "result_whisper = model_whisper.transcribe(audio_file, prompt=prompt_text)\n",
    "end_time = time.time()\n",
    "\n",
    "detected_language = result_whisper.get(\"language\", \"en\")\n",
    "print(f\"\\nDetected language: {detected_language}\")\n",
    "\n",
    "\n",
    "print(\"Loading WhisperX alignment model...\")\n",
    "alignment_model, align_metadata = whisperx.load_align_model(\n",
    "    language_code=detected_language, device=device\n",
    ")\n",
    "\n",
    "audio, sr = librosa.load(audio_file, sr=16000, mono=True)\n",
    "duration_sec = len(audio) / sr\n",
    "print(f\"Loaded audio sr={sr}, duration={duration_sec:.2f}s\")\n",
    "\n",
    "print(\"Aligning Whisper transcript with WhisperX...\")\n",
    "result_aligned = whisperx.align(\n",
    "    transcript=result_whisper[\"segments\"],\n",
    "    model=alignment_model,\n",
    "    align_model_metadata=align_metadata,\n",
    "    audio=audio,\n",
    "    device=device,\n",
    "    return_char_alignments=False\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n--- Word-Level Transcription with Confidence Scores ---\")\n",
    "all_confidences = []\n",
    "low_confidence_words = []\n",
    "confidence_threshold = 0.7\n",
    "\n",
    "for word in result_aligned[\"word_segments\"]:\n",
    "    word_text = word['word'].strip()\n",
    "    start_t = word['start']\n",
    "    end_t = word['end']\n",
    "    confidence = float(word.get('score', word.get('confidence', 0.5)))\n",
    "    all_confidences.append(confidence)\n",
    "    if confidence < confidence_threshold:\n",
    "        low_confidence_words.append((word_text, confidence, start_t))\n",
    "    print(f\"[{start_t:.2f} - {end_t:.2f}] {word_text} (conf: {confidence:.3f})\")\n",
    "\n",
    "transcript_text = \" \".join([w['word'].strip() for w in result_aligned[\"word_segments\"]])\n",
    "transcript_text = \" \".join(transcript_text.split())\n",
    "\n",
    "if all_confidences:\n",
    "    mean_conf = np.mean(all_confidences)\n",
    "    median_conf = np.median(all_confidences)\n",
    "    std_conf = np.std(all_confidences)\n",
    "    print(f\"\\n--- Confidence Statistics ---\")\n",
    "    print(f\"Mean: {mean_conf:.3f}, Median: {median_conf:.3f}, Std: {std_conf:.3f}\")\n",
    "    print(f\"Min: {np.min(all_confidences):.3f}, Max: {np.max(all_confidences):.3f}\")\n",
    "    print(f\"Low-confidence words (< {confidence_threshold}): {len(low_confidence_words)}\")\n",
    "\n",
    "pauses = []\n",
    "total_silence = 0.0\n",
    "\n",
    "for i in range(1, len(result_aligned[\"word_segments\"])):\n",
    "    prev_end = result_aligned[\"word_segments\"][i - 1]['end']\n",
    "    curr_start = result_aligned[\"word_segments\"][i]['start']\n",
    "    pause_dur = curr_start - prev_end\n",
    "    if pause_dur > 0:\n",
    "        pauses.append(pause_dur)\n",
    "        total_silence += pause_dur\n",
    "\n",
    "avg_pause = np.mean(pauses) if pauses else 0.0\n",
    "\n",
    "filler_words_en = {\n",
    "    \"to be honest\", \"kind of\", \"um\", \"ah\", \"huh\", \"and so\", \"so um\", \"uh\",\n",
    "    \"and um\", \"like um\", \"so like\", \"like it's\", \"it's like\", \"i mean\", \"yeah\",\n",
    "    \"ok so\", \"uh so\", \"so uh\", \"yeah so\", \"you know\", \"it's uh\", \"uh and\",\n",
    "    \"and uh\", \"like\", \"kind\"\n",
    "}\n",
    "\n",
    "filler_words_nl = {\n",
    "    \"eh\", \"uh\", \"uuh\", \"uhm\", \"euh\", \"zeg maar\", \"weet je\", \"dus\", \"nou\", \n",
    "    \"toch\", \"zeg maar even\", \"eigenlijk\", \"soort van\", \"om het zo te zeggen\", \n",
    "    \"weet je wel\", \"ja\", \"oké\", \"nou ja\", \"hè\"\n",
    "}\n",
    "\n",
    "if detected_language.startswith(\"nl\"):\n",
    "    filler_list = filler_words_nl\n",
    "    print(\"\\nUsing Dutch filler word list.\")\n",
    "else:\n",
    "    filler_list = filler_words_en\n",
    "    print(\"\\nUsing English filler word list.\")\n",
    "\n",
    "words_text = [w['word'].strip().lower() for w in result_aligned[\"word_segments\"]]\n",
    "\n",
    "filler_count = 0\n",
    "for filler in filler_list:\n",
    "    tokens = filler.split()\n",
    "    n = len(tokens)\n",
    "    for i in range(len(words_text) - n + 1):\n",
    "        if words_text[i:i+n] == tokens:\n",
    "            filler_count += 1\n",
    "\n",
    "filler_percentage = (filler_count / len(words_text)) * 100 if words_text else 0\n",
    "\n",
    "print(\"\\n--- Pause & Filler Analysis ---\")\n",
    "print(f\"Average pause between words: {avg_pause:.2f}s\")\n",
    "print(f\"Total silence duration: {total_silence:.2f}s\")\n",
    "print(f\"Filler word count: {filler_count}\")\n",
    "print(f\"Filler word percentage: {filler_percentage:.2f}%\")\n",
    "\n",
    "\n",
    "wer = jiwer.wer(reference, transcript_text)\n",
    "cer = jiwer.cer(reference, transcript_text)\n",
    "chrf = sacrebleu.sentence_chrf(transcript_text, [reference]).score\n",
    "rtf = (end_time - start_time) / duration_sec\n",
    "\n",
    "print(\"\\n--- Evaluation ---\")\n",
    "print(f\"WER: {wer:.3f}\")\n",
    "print(f\"CER: {cer:.3f}\")\n",
    "print(f\"CHRF: {chrf:.3f}\")\n",
    "print(f\"RTF: {rtf:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65192b3c",
   "metadata": {},
   "source": [
    "The evaluation metrics values show a great performance of the transcription with minimal error. The word-level timestamps are correct and there are confidence levels for each word. The following code is supporting the software a bit more by turning the code into usable functions. This code will be used by the software inetrn to impelment in the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c110b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with Whisper (with prompt)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo X1 Carbon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected language: en\n",
      "Loading WhisperX alignment model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo X1 Carbon\\AppData\\Local\\Temp\\ipykernel_1252\\3140689343.py:33: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio, sr = librosa.load(audio_file, sr=16000, mono=True)\n",
      "c:\\Users\\Lenovo X1 Carbon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded audio sr=16000, duration=31.25s\n",
      "Aligning Whisper transcript with WhisperX...\n",
      "\n",
      "--- Word-Level Transcription with Confidence Scores ---\n",
      "[0.00 - 1.01] Today (conf: 0.627)\n",
      "[1.13 - 1.19] I (conf: 0.869)\n",
      "[1.65 - 1.73] woke (conf: 0.001)\n",
      "[1.75 - 1.97] up, (conf: 0.850)\n",
      "[2.33 - 2.49] ate (conf: 0.631)\n",
      "[2.62 - 2.80] my (conf: 0.930)\n",
      "[2.90 - 3.64] breakfast (conf: 0.856)\n",
      "[4.24 - 4.34] and (conf: 0.687)\n",
      "[4.42 - 4.65] then (conf: 0.925)\n",
      "[4.83 - 5.43] started (conf: 0.529)\n",
      "[5.45 - 5.83] doing (conf: 0.634)\n",
      "[5.99 - 6.22] my (conf: 0.971)\n",
      "[6.32 - 7.02] chores. (conf: 0.768)\n",
      "[7.00 - 7.92] In (conf: 0.984)\n",
      "[7.96 - 8.06] the (conf: 0.878)\n",
      "[8.14 - 8.75] afternoon (conf: 0.923)\n",
      "[8.77 - 8.79] I (conf: 1.000)\n",
      "[9.13 - 9.37] went (conf: 0.910)\n",
      "[9.69 - 9.85] out (conf: 0.956)\n",
      "[10.07 - 10.29] to (conf: 0.442)\n",
      "[10.31 - 10.36] do (conf: 0.480)\n",
      "[10.39 - 10.46] the (conf: 0.991)\n",
      "[10.52 - 11.38] groceries (conf: 0.858)\n",
      "[11.40 - 12.46] and (conf: 0.838)\n",
      "[12.59 - 12.85] after (conf: 0.996)\n",
      "[12.93 - 13.15] that (conf: 0.996)\n",
      "[13.39 - 13.43] I (conf: 0.971)\n",
      "[13.47 - 13.75] met (conf: 0.877)\n",
      "[13.81 - 13.97] with (conf: 0.829)\n",
      "[14.05 - 14.21] my (conf: 0.846)\n",
      "[14.31 - 14.71] friends (conf: 0.787)\n",
      "[14.73 - 14.78] to (conf: 0.500)\n",
      "[15.22 - 15.60] drink (conf: 0.985)\n",
      "[15.72 - 16.02] coffee. (conf: 0.753)\n",
      "[16.00 - 17.01] It (conf: 0.986)\n",
      "[17.07 - 17.19] was (conf: 0.987)\n",
      "[17.27 - 17.53] very (conf: 0.887)\n",
      "[17.57 - 18.05] nice (conf: 0.701)\n",
      "[18.07 - 19.06] and (conf: 0.906)\n",
      "[19.20 - 19.28] I (conf: 0.918)\n",
      "[19.36 - 19.70] liked (conf: 0.929)\n",
      "[19.93 - 20.05] the (conf: 0.664)\n",
      "[20.21 - 20.93] atmosphere (conf: 0.820)\n",
      "[21.11 - 21.17] of (conf: 0.994)\n",
      "[21.21 - 21.34] the (conf: 0.596)\n",
      "[21.40 - 22.02] coffee. (conf: 0.916)\n",
      "[22.00 - 24.95] In (conf: 0.835)\n",
      "[25.01 - 25.11] the (conf: 0.855)\n",
      "[25.23 - 25.62] evening (conf: 0.931)\n",
      "[25.64 - 25.66] I (conf: 0.997)\n",
      "[25.68 - 26.70] went (conf: 0.577)\n",
      "[26.74 - 27.18] home, (conf: 0.895)\n",
      "[28.05 - 28.49] cooked (conf: 0.677)\n",
      "[28.73 - 29.11] dinner (conf: 0.916)\n",
      "[29.33 - 29.45] and (conf: 0.728)\n",
      "[29.55 - 29.75] went (conf: 0.835)\n",
      "[29.82 - 29.91] to (conf: 0.764)\n",
      "[29.98 - 31.02] sleep. (conf: 0.910)\n",
      "\n",
      "--- Confidence Statistics ---\n",
      "Mean: 0.816, Median: 0.863, Std: 0.182\n",
      "Min: 0.001, Max: 1.000\n",
      "Low-confidence words (< 0.7): 13\n",
      "\n",
      "--- Low-confidence words (>= 4 letters) ---\n",
      "Today (conf: 0.627, start: 0.00s)\n",
      "woke (conf: 0.001, start: 1.65s)\n",
      "started (conf: 0.529, start: 4.83s)\n",
      "doing (conf: 0.634, start: 5.45s)\n",
      "went (conf: 0.577, start: 25.68s)\n",
      "cooked (conf: 0.677, start: 28.05s)\n",
      "\n",
      "Using English filler word list.\n",
      "\n",
      "--- Pause & Filler Analysis ---\n",
      "Average pause between words: 0.14s\n",
      "Total silence duration: 7.69s\n",
      "Filler word count: 0\n",
      "Filler word percentage: 0.00%\n",
      "\n",
      "--- Evaluation ---\n",
      "WER: 0.017\n",
      "CER: 0.007\n",
      "CHRF: 98.177\n",
      "RTF: 1.893\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import whisperx\n",
    "import time\n",
    "import jiwer\n",
    "import sacrebleu\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "audio_file = \"Noisy.m4a\"\n",
    "device = \"cpu\"\n",
    "\n",
    "prompt_text = (\n",
    "    \"Fontys University, Eindhoven, Netherlands\"\n",
    ")\n",
    "\n",
    "reference = \"\"\"Today I woke up, ate my braekfast and then started doing my chores. In the afternoon I went out to do the groceries and after that I met with my friends to drink coffee. It was very nice and I liked the atmosphere of the coffee. In the evening I went home, cooked dinner and went to sleep.\"\"\"\n",
    "\n",
    "print(\"Transcribing with Whisper (with prompt)...\")\n",
    "model_whisper = whisper.load_model(\"medium\", device=device)\n",
    "\n",
    "start_time = time.time()\n",
    "result_whisper = model_whisper.transcribe(audio_file, prompt=prompt_text)\n",
    "end_time = time.time()\n",
    "\n",
    "detected_language = result_whisper.get(\"language\", \"en\")\n",
    "print(f\"\\nDetected language: {detected_language}\")\n",
    "\n",
    "print(\"Loading WhisperX alignment model...\")\n",
    "alignment_model, align_metadata = whisperx.load_align_model(\n",
    "    language_code=detected_language, device=device\n",
    ")\n",
    "\n",
    "audio, sr = librosa.load(audio_file, sr=16000, mono=True)\n",
    "duration_sec = len(audio) / sr\n",
    "print(f\"Loaded audio sr={sr}, duration={duration_sec:.2f}s\")\n",
    "\n",
    "print(\"Aligning Whisper transcript with WhisperX...\")\n",
    "result_aligned = whisperx.align(\n",
    "    transcript=result_whisper[\"segments\"],\n",
    "    model=alignment_model,\n",
    "    align_model_metadata=align_metadata,\n",
    "    audio=audio,\n",
    "    device=device,\n",
    "    return_char_alignments=False\n",
    ")\n",
    "\n",
    "print(\"\\n--- Word-Level Transcription with Confidence Scores ---\")\n",
    "all_confidences = []\n",
    "low_confidence_words = []\n",
    "low_confidence_long_words = []   # NEW\n",
    "confidence_threshold = 0.7\n",
    "\n",
    "for word in result_aligned[\"word_segments\"]:\n",
    "    word_text = word['word'].strip()\n",
    "    start_t = word['start']\n",
    "    end_t = word['end']\n",
    "    confidence = float(word.get('score', word.get('confidence', 0.5)))\n",
    "\n",
    "    all_confidences.append(confidence)\n",
    "\n",
    "    if confidence < confidence_threshold:\n",
    "        low_confidence_words.append((word_text, confidence, start_t))\n",
    "\n",
    "    if confidence < confidence_threshold and len(word_text) >= 4:\n",
    "        low_confidence_long_words.append((word_text, confidence, start_t))\n",
    "\n",
    "    print(f\"[{start_t:.2f} - {end_t:.2f}] {word_text} (conf: {confidence:.3f})\")\n",
    "\n",
    "transcript_text = \" \".join([w['word'].strip() for w in result_aligned[\"word_segments\"]])\n",
    "transcript_text = \" \".join(transcript_text.split())\n",
    "\n",
    "if all_confidences:\n",
    "    mean_conf = np.mean(all_confidences)\n",
    "    median_conf = np.median(all_confidences)\n",
    "    std_conf = np.std(all_confidences)\n",
    "    print(f\"\\n--- Confidence Statistics ---\")\n",
    "    print(f\"Mean: {mean_conf:.3f}, Median: {median_conf:.3f}, Std: {std_conf:.3f}\")\n",
    "    print(f\"Min: {np.min(all_confidences):.3f}, Max: {np.max(all_confidences):.3f}\")\n",
    "    print(f\"Low-confidence words (< {confidence_threshold}): {len(low_confidence_words)}\")\n",
    "\n",
    "print(\"\\n--- Low-confidence words (>= 4 letters) ---\")\n",
    "for w, c, t in low_confidence_long_words:\n",
    "    print(f\"{w} (conf: {c:.3f}, start: {t:.2f}s)\")\n",
    "\n",
    "# Pause analysis\n",
    "pauses = []\n",
    "total_silence = 0.0\n",
    "\n",
    "for i in range(1, len(result_aligned[\"word_segments\"])):    \n",
    "    prev_end = result_aligned[\"word_segments\"][i - 1]['end']\n",
    "    curr_start = result_aligned[\"word_segments\"][i]['start']\n",
    "    pause_dur = curr_start - prev_end\n",
    "    if pause_dur > 0:\n",
    "        pauses.append(pause_dur)\n",
    "        total_silence += pause_dur\n",
    "\n",
    "avg_pause = np.mean(pauses) if pauses else 0.0\n",
    "\n",
    "filler_words_en = {\n",
    "    \"to be honest\", \"kind of\", \"um\", \"ah\", \"huh\", \"and so\", \"so um\", \"uh\",\n",
    "    \"and um\", \"like um\", \"so like\", \"like it's\", \"it's like\", \"i mean\", \"yeah\",\n",
    "    \"ok so\", \"uh so\", \"so uh\", \"yeah so\", \"you know\", \"it's uh\", \"uh and\",\n",
    "    \"and uh\", \"like\", \"kind\"\n",
    "}\n",
    "\n",
    "filler_words_nl = {\n",
    "    \"eh\", \"uh\", \"uuh\", \"uhm\", \"euh\", \"zeg maar\", \"weet je\", \"dus\", \"nou\",\n",
    "    \"toch\", \"zeg maar even\", \"eigenlijk\", \"soort van\", \"om het zo te zeggen\",\n",
    "    \"weet je wel\", \"ja\", \"oké\", \"nou ja\", \"hè\"\n",
    "}\n",
    "\n",
    "if detected_language.startswith(\"nl\"):\n",
    "    filler_list = filler_words_nl\n",
    "    print(\"\\nUsing Dutch filler word list.\")\n",
    "else:\n",
    "    filler_list = filler_words_en\n",
    "    print(\"\\nUsing English filler word list.\")\n",
    "\n",
    "words_text = [w['word'].strip().lower() for w in result_aligned[\"word_segments\"]]\n",
    "\n",
    "filler_count = 0\n",
    "for filler in filler_list:\n",
    "    tokens = filler.split()\n",
    "    n = len(tokens)\n",
    "    for i in range(len(words_text) - n + 1):\n",
    "        if words_text[i:i+n] == tokens:\n",
    "            filler_count += 1\n",
    "\n",
    "filler_percentage = (filler_count / len(words_text)) * 100 if words_text else 0\n",
    "\n",
    "print(\"\\n--- Pause & Filler Analysis ---\")\n",
    "print(f\"Average pause between words: {avg_pause:.2f}s\")\n",
    "print(f\"Total silence duration: {total_silence:.2f}s\")\n",
    "print(f\"Filler word count: {filler_count}\")\n",
    "print(f\"Filler word percentage: {filler_percentage:.2f}%\")\n",
    "\n",
    "# Evaluation\n",
    "wer = jiwer.wer(reference, transcript_text)\n",
    "cer = jiwer.cer(reference, transcript_text)\n",
    "chrf = sacrebleu.sentence_chrf(transcript_text, [reference]).score\n",
    "rtf = (end_time - start_time) / duration_sec\n",
    "\n",
    "print(\"\\n--- Evaluation ---\")\n",
    "print(f\"WER: {wer:.3f}\")\n",
    "print(f\"CER: {cer:.3f}\")\n",
    "print(f\"CHRF: {chrf:.3f}\")\n",
    "print(f\"RTF: {rtf:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7837e6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with Whisper (with prompt)...\n",
      "\n",
      "Detected language: en\n",
      "Loading WhisperX alignment model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo X1 Carbon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\Lenovo X1 Carbon\\AppData\\Local\\Temp\\ipykernel_3552\\1077964265.py:25: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio, sr = librosa.load(audio_file, sr=16000, mono=True)\n",
      "c:\\Users\\Lenovo X1 Carbon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded audio sr=16000, duration=16.47s\n",
      "Aligning Whisper transcript with WhisperX...\n",
      "\n",
      "--- Word-Level Transcription with Confidence Scores ---\n",
      "[0.00 - 0.88] I (conf: 0.976)\n",
      "[0.92 - 1.10] have (conf: 0.934)\n",
      "[1.12 - 1.58] 10 (conf: 0.862)\n",
      "[1.62 - 1.99] million (conf: 0.894)\n",
      "[2.08 - 2.45] euros (conf: 0.814)\n",
      "[2.53 - 2.59] in (conf: 0.938)\n",
      "[2.65 - 2.77] my (conf: 0.996)\n",
      "[2.81 - 3.09] bank (conf: 0.867)\n",
      "[3.15 - 3.57] account (conf: 0.826)\n",
      "[3.75 - 3.85] and (conf: 0.886)\n",
      "[3.95 - 4.01] I (conf: 0.890)\n",
      "[4.27 - 4.39] owe (conf: 0.979)\n",
      "[4.49 - 4.69] my (conf: 0.826)\n",
      "[4.79 - 5.13] mom (conf: 0.860)\n",
      "[5.15 - 6.24] 10k. (conf: 0.920)\n",
      "[6.98 - 7.60] Yesterday (conf: 0.932)\n",
      "[7.62 - 7.66] in (conf: 0.500)\n",
      "[7.68 - 8.22] the (conf: 0.861)\n",
      "[8.24 - 8.62] store (conf: 0.857)\n",
      "[8.66 - 8.86] the (conf: 0.455)\n",
      "[8.90 - 9.18] milk (conf: 0.940)\n",
      "[9.26 - 9.52] was (conf: 0.880)\n",
      "[9.54 - 9.56] 5 (conf: 0.999)\n",
      "[9.58 - 10.67] euros (conf: 0.714)\n",
      "[10.69 - 11.19] 50 (conf: 0.853)\n",
      "[11.21 - 13.89] and (conf: 0.523)\n",
      "[13.96 - 14.04] the (conf: 0.969)\n",
      "[14.10 - 14.34] bread (conf: 0.986)\n",
      "[14.44 - 14.60] was (conf: 0.993)\n",
      "[14.62 - 14.64] 2 (conf: 1.000)\n",
      "[14.88 - 16.02] euro. (conf: 0.785)\n",
      "\n",
      "--- Full Transcript ---\n",
      "I have 10 million euros in my bank account and I owe my mom 10k. Yesterday in the store the milk was 5 euros 50 and the bread was 2 euro.\n",
      "\n",
      "Transcription completed in 44.23s\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import whisperx\n",
    "import time\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "audio_file = \"Money.m4a\"\n",
    "device = \"cpu\"\n",
    "\n",
    "prompt_text = \"Fontys University, Eindhoven, Netherlands\"\n",
    "\n",
    "print(\"Transcribing with Whisper (with prompt)...\")\n",
    "model_whisper = whisper.load_model(\"medium\", device=device)\n",
    "\n",
    "start_time = time.time()\n",
    "result_whisper = model_whisper.transcribe(audio_file, prompt=prompt_text)\n",
    "end_time = time.time()\n",
    "\n",
    "detected_language = result_whisper.get(\"language\", \"en\")\n",
    "print(f\"\\nDetected language: {detected_language}\")\n",
    "\n",
    "print(\"Loading WhisperX alignment model...\")\n",
    "alignment_model, align_metadata = whisperx.load_align_model(language_code=detected_language, device=device)\n",
    "\n",
    "audio, sr = librosa.load(audio_file, sr=16000, mono=True)\n",
    "duration_sec = len(audio) / sr\n",
    "print(f\"Loaded audio sr={sr}, duration={duration_sec:.2f}s\")\n",
    "\n",
    "print(\"Aligning Whisper transcript with WhisperX...\")\n",
    "result_aligned = whisperx.align(\n",
    "transcript=result_whisper[\"segments\"],\n",
    "model=alignment_model,\n",
    "align_model_metadata=align_metadata,\n",
    "audio=audio,\n",
    "device=device,\n",
    "return_char_alignments=False\n",
    ")\n",
    "\n",
    "print(\"\\n--- Word-Level Transcription with Confidence Scores ---\")\n",
    "for word in result_aligned[\"word_segments\"]:\n",
    "    word_text = word['word'].strip()\n",
    "    start_t = word['start']\n",
    "    end_t = word['end']\n",
    "    confidence = float(word.get('score', word.get('confidence', 0.5)))\n",
    "    print(f\"[{start_t:.2f} - {end_t:.2f}] {word_text} (conf: {confidence:.3f})\")\n",
    "\n",
    "    transcript_text = \" \".join([w['word'].strip() for w in result_aligned[\"word_segments\"]])\n",
    "    transcript_text = \" \".join(transcript_text.split())\n",
    "\n",
    "print(\"\\n--- Full Transcript ---\")\n",
    "print(transcript_text)\n",
    "\n",
    "print(f\"\\nTranscription completed in {end_time - start_time:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8931117",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccd5047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import whisperx\n",
    "import librosa\n",
    "import numpy as np\n",
    "import string \n",
    "\n",
    "# Helper Functions\n",
    "\n",
    "def load_models(device=\"cpu\", whisper_model_size=\"medium\"):\n",
    "    \"\"\"Load Whisper and WhisperX alignment models.\"\"\"\n",
    "    model_whisper = whisper.load_model(whisper_model_size, device=device)\n",
    "    return model_whisper, device\n",
    "\n",
    "def transcribe_audio(model_whisper, audio_file, prompt_text=\"\", device=\"cpu\"):\n",
    "    \"\"\"Transcribe audio using Whisper with optional prompt.\"\"\"\n",
    "    result = model_whisper.transcribe(audio_file, prompt=prompt_text)\n",
    "    language = result.get(\"language\", \"en\")\n",
    "    return result, language\n",
    "\n",
    "def align_transcript(result_whisper, language_code, audio_file, device=\"cpu\"):\n",
    "    \"\"\"Align Whisper transcript with WhisperX to get word-level info.\"\"\"\n",
    "    alignment_model, align_metadata = whisperx.load_align_model(\n",
    "        language_code=language_code, device=device\n",
    "    )\n",
    "    audio, sr = librosa.load(audio_file, sr=16000, mono=True)\n",
    "    duration_sec = len(audio) / sr\n",
    "    result_aligned = whisperx.align(\n",
    "        transcript=result_whisper[\"segments\"],\n",
    "        model=alignment_model,\n",
    "        align_model_metadata=align_metadata,\n",
    "        audio=audio,\n",
    "        device=device,\n",
    "        return_char_alignments=False\n",
    "    )\n",
    "    return result_aligned, audio, sr, duration_sec\n",
    "\n",
    "def compute_pause_stats(word_segments):\n",
    "    \"\"\"Compute average pause and total silence between words.\"\"\"\n",
    "    pauses = []\n",
    "    total_silence = 0.0\n",
    "    for i in range(1, len(word_segments)):\n",
    "        prev_end = word_segments[i-1]['end']\n",
    "        curr_start = word_segments[i]['start']\n",
    "        pause_dur = curr_start - prev_end\n",
    "        if pause_dur > 0:\n",
    "            pauses.append(pause_dur)\n",
    "            total_silence += pause_dur\n",
    "    avg_pause = np.mean(pauses) if pauses else 0.0\n",
    "    return avg_pause, total_silence\n",
    "\n",
    "def detect_fillers(word_segments, language_code):\n",
    "    \"\"\"Count filler words in the transcript, ignoring punctuation, and return detected fillers.\"\"\"\n",
    "\n",
    "    filler_words_en = {\n",
    "        \"to be honest\", \"kind of\", \"um\", \"ah\", \"huh\", \"and so\", \"so um\", \"uh\",\n",
    "        \"and um\", \"like um\", \"so like\", \"like it's\", \"it's like\", \"i mean\", \"yeah\",\n",
    "        \"ok so\", \"uh so\", \"so uh\", \"yeah so\", \"you know\", \"it's uh\", \"uh and\",\n",
    "        \"and uh\", \"like\", \"kind\", \"well\", \"actually\", \"basically\", \"literally\",\n",
    "        \"you see\", \"right\", \"so\", \"okay\", \"alright\", \"you know what I mean\", \n",
    "        \"I guess\", \"I think\", \"I mean\", \"anyway\", \"just\", \"so yeah\", \"so okay\",\n",
    "        \"umm\", \"hmm\"\n",
    "    }\n",
    "\n",
    "    filler_words_nl = {\n",
    "        \"eh\", \"uh\", \"uuh\", \"uhm\", \"euh\", \"zeg maar\", \"weet je\", \"dus\", \"nou\", \n",
    "        \"toch\", \"zeg maar even\", \"eigenlijk\", \"soort van\", \"om het zo te zeggen\", \n",
    "        \"weet je wel\", \"ja\", \"oké\", \"nou ja\", \"hè\", \"inderdaad\", \"juist\", \"precies\",\n",
    "        \"dus ja\", \"maar ja\", \"zeg\", \"ehm\", \"hm\", \"ok\", \"oké dan\"\n",
    "    }\n",
    "\n",
    "    filler_list = filler_words_nl if language_code.startswith(\"nl\") else filler_words_en\n",
    "\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    words_text = [w['word'].strip().lower().translate(translator) for w in word_segments]\n",
    "\n",
    "    filler_count = 0\n",
    "    detected_fillers = []\n",
    "\n",
    "    for filler in filler_list:\n",
    "        \n",
    "        tokens = [t.translate(translator) for t in filler.lower().split()]\n",
    "        n = len(tokens)\n",
    "        for i in range(len(words_text) - n + 1):\n",
    "            if words_text[i:i+n] == tokens:\n",
    "                filler_count += 1\n",
    "                \n",
    "                detected_fillers.append(\" \".join(words_text[i:i+n]))\n",
    "\n",
    "    filler_percentage = (filler_count / len(words_text)) * 100 if words_text else 0\n",
    "\n",
    "    return filler_count, filler_percentage, detected_fillers\n",
    "\n",
    "def extract_word_info(word_segments, confidence_threshold=0.7):\n",
    "    \"\"\"Extract word-level text, timestamps, and confidence scores.\"\"\"\n",
    "    word_data = []\n",
    "    low_conf_words = []\n",
    "    all_confidences = []\n",
    "    \n",
    "    for word in word_segments:\n",
    "        text = word['word'].strip()\n",
    "        start = word['start']\n",
    "        end = word['end']\n",
    "        confidence = float(word.get('score', word.get('confidence', 0.5)))\n",
    "        all_confidences.append(confidence)\n",
    "        if confidence < confidence_threshold:\n",
    "            low_conf_words.append((text, confidence, start))\n",
    "        word_data.append({\n",
    "            \"word\": text,\n",
    "            \"start\": start,\n",
    "            \"end\": end,\n",
    "            \"confidence\": confidence\n",
    "        })\n",
    "    return word_data, all_confidences, low_conf_words\n",
    "\n",
    "# Main Pipeline Function\n",
    "\n",
    "def process_audio(audio_file, prompt_text=\"\", device=\"cpu\"):\n",
    "    model_whisper, device = load_models(device=device)\n",
    "    \n",
    "    result_whisper, language_code = transcribe_audio(model_whisper, audio_file, prompt_text, device)\n",
    "    \n",
    "    result_aligned, audio, sr, duration_sec = align_transcript(result_whisper, language_code, audio_file, device)\n",
    "    \n",
    "    word_data, all_confidences, low_conf_words = extract_word_info(result_aligned[\"word_segments\"])\n",
    "    \n",
    "    avg_pause, total_silence = compute_pause_stats(result_aligned[\"word_segments\"])\n",
    "    \n",
    "    filler_count, filler_percentage = detect_fillers(result_aligned[\"word_segments\"], language_code)\n",
    "    \n",
    "    transcript_text = \" \".join([w['word'].strip() for w in result_aligned[\"word_segments\"]])\n",
    "    transcript_text = \" \".join(transcript_text.split())\n",
    "    \n",
    "    return {\n",
    "        \"transcript\": transcript_text,\n",
    "        \"word_data\": word_data,\n",
    "        \"avg_pause\": avg_pause,\n",
    "        \"total_silence\": total_silence,\n",
    "        \"filler_count\": filler_count,\n",
    "        \"filler_percentage\": filler_percentage,\n",
    "        \"language\": language_code\n",
    "    }\n",
    "\n",
    "# Example Usage-\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    audio_file = \"TestAudio.m4a\"\n",
    "    prompt_text = \"Fontys University, Eindhoven, Netherlands\"\n",
    "    \n",
    "    results = process_audio(audio_file, prompt_text)\n",
    "    \n",
    "    print(f\"\\nDetected language: {results['language']}\")\n",
    "    print(f\"Transcript:\\n{results['transcript']}\")\n",
    "    print(f\"\\n--- Word-Level Info ---\")\n",
    "    for w in results['word_data']:\n",
    "        print(f\"[{w['start']:.2f}-{w['end']:.2f}] {w['word']} (conf: {w['confidence']:.3f})\")\n",
    "    \n",
    "    print(f\"\\n--- Pause & Filler Stats ---\")\n",
    "    print(f\"Average pause: {results['avg_pause']:.2f}s\")\n",
    "    print(f\"Total silence: {results['total_silence']:.2f}s\")\n",
    "    print(f\"Filler words: {results['filler_count']}\")\n",
    "    print(f\"Filler word %: {results['filler_percentage']:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
