{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f000154",
   "metadata": {},
   "source": [
    "## Semantic search\n",
    "\n",
    "In this notebook I am going to put the pieces I already have together - transcription, alignment and topic segmentation and I will try out semantic search on top of that.\n",
    "\n",
    "I will use a random aduio file in english."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f30e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo X1 Carbon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\Lenovo X1 Carbon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\speechbrain\\utils\\torch_audio_backend.py:57: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  available_backends = torchaudio.list_audio_backends()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No language specified, language will be first be detected for each audio file (increases inference time).\n",
      ">>Performing voice activity detection using Pyannote...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo X1 Carbon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\inspect.py:988: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  if ismodule(module) and hasattr(module, '__file__'):\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.5.5. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint c:\\Users\\Lenovo X1 Carbon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\whisperx\\assets\\pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.4.0. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.8.0+cpu. Bad things might happen unless you revert torch to 1.x.\n",
      "Detected language: en (0.96) in first 30s of audio...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo X1 Carbon\\AppData\\Local\\Temp\\ipykernel_130980\\1774229892.py:27: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio, sr = librosa.load(audio_file, sr=16000, mono=True)\n",
      "c:\\Users\\Lenovo X1 Carbon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded audio sr=16000, duration=278.01s\n",
      "[0.03 - 0.25] I\n",
      "[0.29 - 0.43] want\n",
      "[0.45 - 0.53] to\n",
      "[0.59 - 0.83] talk\n",
      "[0.89 - 1.39] about\n",
      "[1.43 - 2.23] beating\n",
      "[2.25 - 2.68] stress\n",
      "[2.72 - 3.02] today.\n",
      "[3.06 - 4.74] You\n",
      "[4.78 - 4.98] know,\n",
      "[5.60 - 5.84] live\n",
      "[5.88 - 6.06] here\n",
      "[6.10 - 6.18] in\n",
      "[6.24 - 6.42] Hong\n",
      "[6.44 - 6.72] Kong\n",
      "[6.74 - 6.78] is\n",
      "[6.84 - 7.08] very\n",
      "[7.14 - 7.75] stressful,\n",
      "[7.85 - 8.09] so\n",
      "[8.11 - 8.13] I\n",
      "[8.71 - 8.85] think\n",
      "[9.01 - 9.37] today's\n",
      "[9.45 - 9.89] topic\n",
      "[9.97 - 10.03] is\n",
      "[10.11 - 10.29] very\n",
      "[10.41 - 10.75] useful\n",
      "[10.79 - 10.91] for\n",
      "[11.03 - 11.35] everyone\n",
      "[11.41 - 11.73] because\n",
      "[12.97 - 13.08] we\n",
      "[13.10 - 13.26] can\n",
      "[13.34 - 13.48] do\n",
      "[13.52 - 13.92] something\n",
      "[14.00 - 14.38] about\n",
      "[14.42 - 14.86] it\n",
      "[15.80 - 16.00] just\n",
      "[16.04 - 16.12] to\n",
      "[16.18 - 16.36] cope\n",
      "[16.38 - 16.52] with\n",
      "[16.56 - 16.66] the\n",
      "[16.68 - 17.58] stress.\n",
      "[17.56 - 18.34] So\n",
      "[18.73 - 18.95] maybe\n",
      "[19.01 - 19.13] you\n",
      "[19.19 - 19.37] have\n",
      "[19.47 - 19.69] some\n",
      "[19.95 - 20.35] change\n",
      "[20.55 - 20.63] in\n",
      "[20.67 - 20.85] your\n",
      "[20.95 - 21.27] life,\n",
      "[21.53 - 21.77] maybe\n",
      "[21.81 - 22.17] big\n",
      "[22.19 - 22.55] change\n",
      "[22.61 - 22.65] or\n",
      "[22.71 - 22.99] small\n",
      "[23.07 - 23.47] change,\n",
      "[23.91 - 24.09] but\n",
      "[24.11 - 24.84] instead\n",
      "[24.92 - 24.96] of\n",
      "[25.04 - 25.24] being\n",
      "[25.34 - 25.78] afraid,\n",
      "[25.80 - 25.82] I\n",
      "[27.08 - 27.24] think\n",
      "[27.28 - 27.38] you\n",
      "[27.42 - 27.60] should\n",
      "[27.64 - 27.74] have\n",
      "[27.80 - 27.82] a\n",
      "[27.88 - 28.28] positive\n",
      "[28.40 - 28.76] attitude\n",
      "[28.82 - 28.90] and\n",
      "[28.98 - 29.22] think\n",
      "[29.32 - 29.38] of\n",
      "[29.60 - 29.92] change\n",
      "[30.06 - 30.14] as\n",
      "[30.25 - 30.29] a\n",
      "[30.34 - 30.64] normal\n",
      "[30.68 - 30.91] part\n",
      "[30.99 - 31.05] of\n",
      "[31.09 - 31.19] life.\n",
      "[32.43 - 32.53] And\n",
      "[32.59 - 32.65] I\n",
      "[32.71 - 32.95] think\n",
      "[33.25 - 33.55] maybe\n",
      "[33.59 - 34.37] here\n",
      "[34.45 - 34.53] in\n",
      "[34.61 - 34.87] Hong\n",
      "[34.91 - 35.25] Kong,\n",
      "[35.29 - 35.39] the\n",
      "[35.45 - 35.95] family\n",
      "[36.27 - 36.40] are\n",
      "[36.66 - 37.20] crafted\n",
      "[37.52 - 38.00] into\n",
      "[38.12 - 38.20] a\n",
      "[38.24 - 38.60] very\n",
      "[38.68 - 39.04] small\n",
      "[39.12 - 39.58] housing\n",
      "[39.62 - 40.28] space.\n",
      "[40.26 - 40.92] So\n",
      "[41.02 - 41.24] maybe\n",
      "[41.28 - 41.38] you\n",
      "[41.56 - 41.65] will\n",
      "[41.80 - 42.15] sometimes\n",
      "[42.17 - 42.61] argue\n",
      "[42.65 - 42.75] with\n",
      "[42.79 - 42.93] your\n",
      "[42.99 - 43.41] family\n",
      "[43.87 - 43.95] and\n",
      "[44.01 - 44.05] I\n",
      "[44.11 - 44.27] think\n",
      "[44.31 - 44.69] try\n",
      "[44.73 - 44.83] to\n",
      "[44.89 - 45.41] resolve\n",
      "[45.45 - 45.66] the\n",
      "[45.88 - 46.52] disagreement\n",
      "[46.56 - 46.68] with\n",
      "[46.78 - 47.20] people\n",
      "[47.22 - 47.26] is\n",
      "[47.98 - 48.16] very\n",
      "[48.22 - 48.74] important\n",
      "[48.84 - 49.12] because\n",
      "[49.20 - 49.38] then\n",
      "[49.42 - 49.55] you\n",
      "[49.59 - 49.77] can\n",
      "[50.09 - 50.39] build\n",
      "[50.45 - 51.05] strong\n",
      "[51.11 - 51.83] relationships\n",
      "[52.31 - 52.41] and\n",
      "[52.59 - 52.85] keep\n",
      "[53.96 - 54.62] commitments\n",
      "[54.76 - 54.90] you\n",
      "[54.96 - 55.12] have\n",
      "[55.24 - 56.04] made.\n",
      "[56.02 - 56.28] For\n",
      "[56.30 - 56.76] example,\n",
      "[56.80 - 57.28] sometimes\n",
      "[57.66 - 57.90] maybe\n",
      "[57.94 - 58.10] you\n",
      "[58.22 - 58.48] feel\n",
      "[58.51 - 58.97] you're\n",
      "[58.98 - 59.27] feeling\n",
      "[59.37 - 59.73] alone\n",
      "[60.37 - 60.45] and\n",
      "[60.53 - 60.67] you\n",
      "[60.71 - 60.91] want\n",
      "[60.95 - 61.05] to\n",
      "[61.23 - 61.41] make\n",
      "[61.45 - 61.65] some\n",
      "[61.75 - 62.31] comfort\n",
      "[62.93 - 63.03] and\n",
      "[63.11 - 63.15] I\n",
      "[63.21 - 63.43] think\n",
      "[64.69 - 64.79] you\n",
      "[64.83 - 64.97] can\n",
      "[65.13 - 65.29] ask\n",
      "[65.35 - 65.45] the\n",
      "[65.49 - 65.75] people\n",
      "[65.79 - 66.01] you\n",
      "[66.11 - 66.47] trust\n",
      "[67.03 - 67.19] for\n",
      "[67.27 - 67.52] help\n",
      "[67.66 - 67.73] is\n",
      "[67.88 - 68.32] very\n",
      "[69.22 - 69.68] important\n",
      "[69.72 - 70.04] because\n",
      "[70.08 - 70.90] if\n",
      "[70.94 - 71.10] you\n",
      "[71.14 - 71.30] have\n",
      "[71.56 - 71.60] a\n",
      "[72.00 - 72.26] bunch\n",
      "[72.34 - 72.40] of\n",
      "[72.54 - 72.94] friends\n",
      "[73.44 - 73.60] they\n",
      "[73.62 - 73.78] can\n",
      "[73.82 - 74.14] listen\n",
      "[74.18 - 74.30] to\n",
      "[74.34 - 74.54] you\n",
      "[74.58 - 75.12] then\n",
      "[75.16 - 75.26] you\n",
      "[75.30 - 75.48] can\n",
      "[75.56 - 76.10] release\n",
      "[76.30 - 76.48] some\n",
      "[76.53 - 77.03] stress\n",
      "[77.99 - 78.35] through\n",
      "[78.37 - 79.29] talking\n",
      "[79.37 - 79.51] to\n",
      "[79.59 - 80.63] them.\n",
      "[80.61 - 81.03] And\n",
      "[81.07 - 81.35] do\n",
      "[81.39 - 81.47] you\n",
      "[81.53 - 81.69] know\n",
      "[81.77 - 81.93] that\n",
      "[82.19 - 82.51] actually\n",
      "[82.63 - 82.75] I\n",
      "[82.81 - 83.01] find\n",
      "[83.07 - 83.13] a\n",
      "[83.21 - 83.57] very\n",
      "[84.71 - 85.05] funny\n",
      "[85.13 - 85.35] thing\n",
      "[85.41 - 85.61] that\n",
      "[86.52 - 86.56] if\n",
      "[86.59 - 86.78] you\n",
      "[86.80 - 86.95] want\n",
      "[86.97 - 87.02] to\n",
      "[87.08 - 87.60] reduce\n",
      "[87.66 - 87.90] some\n",
      "[87.92 - 88.64] stress,\n",
      "[88.66 - 88.78] you\n",
      "[88.82 - 88.98] can\n",
      "[89.04 - 89.46] reduce\n",
      "[89.54 - 89.62] it\n",
      "[89.76 - 90.02] by\n",
      "[90.06 - 90.18] the\n",
      "[90.22 - 90.46] word\n",
      "[90.80 - 92.74] S-T-R-E-S-S,\n",
      "[92.76 - 92.96] that\n",
      "[93.08 - 93.50] stress.\n",
      "[94.44 - 94.56] How\n",
      "[94.58 - 94.76] about\n",
      "[94.80 - 95.02] let's\n",
      "[95.08 - 95.40] begin\n",
      "[95.44 - 95.58] with\n",
      "[95.66 - 95.76] the\n",
      "[96.06 - 96.22] S?\n",
      "[96.77 - 96.94] Well,\n",
      "[97.05 - 97.08] I\n",
      "[97.12 - 97.28] think\n",
      "[97.50 - 97.65] S\n",
      "[98.17 - 98.37] is\n",
      "[98.47 - 98.71] that\n",
      "[98.79 - 98.95] you\n",
      "[98.99 - 99.21] can\n",
      "[99.67 - 99.87] have\n",
      "[99.95 - 100.07] the\n",
      "[100.11 - 100.77] scheduling.\n",
      "[101.81 - 101.93] For\n",
      "[102.05 - 102.69] example,\n",
      "[102.73 - 102.83] you\n",
      "[102.87 - 103.07] don't\n",
      "[103.25 - 103.41] have\n",
      "[103.45 - 103.57] to\n",
      "[103.77 - 104.25] schedule\n",
      "[104.31 - 104.55] too\n",
      "[104.71 - 104.91] many\n",
      "[104.97 - 105.21] things\n",
      "[105.35 - 105.41] in\n",
      "[105.45 - 105.61] your\n",
      "[105.75 - 106.41] day.\n",
      "[106.39 - 106.94] And\n",
      "[106.97 - 107.23] if\n",
      "[107.28 - 107.48] you\n",
      "[107.50 - 107.68] feel\n",
      "[107.72 - 107.92] you're\n",
      "[107.94 - 108.14] too\n",
      "[108.22 - 108.66] busy,\n",
      "[109.62 - 109.70] you\n",
      "[109.74 - 109.84] can\n",
      "[109.88 - 110.06] cut\n",
      "[110.22 - 110.32] out\n",
      "[110.34 - 110.38] an\n",
      "[110.46 - 111.06] activity\n",
      "[111.20 - 111.30] or\n",
      "[111.38 - 111.68] two.\n",
      "[112.40 - 112.56] And\n",
      "[112.94 - 113.06] how\n",
      "[113.10 - 113.26] about\n",
      "[113.30 - 113.38] the\n",
      "[113.52 - 113.82] T\n",
      "[113.88 - 114.25] word?\n",
      "[114.67 - 114.77] The\n",
      "[114.87 - 115.11] T\n",
      "[115.15 - 115.39] word\n",
      "[115.67 - 115.81] is\n",
      "[115.85 - 116.71] treat\n",
      "[116.85 - 117.01] your\n",
      "[117.09 - 117.39] body\n",
      "[117.47 - 117.75] well.\n",
      "[118.49 - 118.75] Because\n",
      "[118.83 - 119.45] experts\n",
      "[119.55 - 119.81] say\n",
      "[119.89 - 120.01] that\n",
      "[120.05 - 120.85] exercise\n",
      "[121.08 - 121.25] can\n",
      "[121.31 - 121.69] reduce\n",
      "[121.72 - 122.16] stress.\n",
      "[122.38 - 122.48] And\n",
      "[122.60 - 122.96] also\n",
      "[123.54 - 123.60] if\n",
      "[123.64 - 123.82] you\n",
      "[124.12 - 124.28] eat\n",
      "[124.54 - 124.84] healthy\n",
      "[124.90 - 125.20] food,\n",
      "[126.06 - 126.22] then\n",
      "[126.28 - 126.44] your\n",
      "[126.52 - 126.86] brain\n",
      "[126.96 - 127.04] and\n",
      "[127.08 - 127.22] your\n",
      "[127.26 - 127.58] body\n",
      "[127.68 - 127.86] get\n",
      "[127.92 - 128.08] the\n",
      "[128.78 - 129.43] nourishment\n",
      "[129.57 - 129.71] they\n",
      "[129.81 - 130.75] need.\n",
      "[130.73 - 131.45] And\n",
      "[131.49 - 132.45] the\n",
      "[132.51 - 132.79] word\n",
      "[133.03 - 133.13] is\n",
      "[133.51 - 133.63] R,\n",
      "[133.65 - 133.83] the\n",
      "[133.93 - 134.25] extra\n",
      "[134.33 - 134.41] is\n",
      "[134.67 - 134.77] R.\n",
      "[135.31 - 135.40] R\n",
      "[135.74 - 135.84] is\n",
      "[135.98 - 136.28] very\n",
      "[136.38 - 136.90] important.\n",
      "[137.18 - 137.28] It\n",
      "[137.34 - 137.62] says\n",
      "[137.70 - 139.46] relax.\n",
      "[140.00 - 140.12] You\n",
      "[140.16 - 140.32] can\n",
      "[140.42 - 140.58] do\n",
      "[140.60 - 140.76] an\n",
      "[140.84 - 141.32] activity\n",
      "[141.34 - 141.56] you\n",
      "[141.65 - 142.09] enjoy\n",
      "[142.22 - 142.31] or\n",
      "[142.33 - 142.67] that\n",
      "[142.71 - 143.33] relaxes\n",
      "[143.41 - 143.63] you.\n",
      "[144.59 - 144.85] Maybe\n",
      "[144.89 - 144.99] you\n",
      "[145.03 - 145.15] can\n",
      "[145.19 - 145.35] read\n",
      "[145.41 - 145.43] a\n",
      "[145.51 - 145.69] good\n",
      "[145.75 - 146.09] book\n",
      "[146.27 - 146.35] or\n",
      "[146.39 - 146.69] learn\n",
      "[146.75 - 146.77] a\n",
      "[146.89 - 147.15] new\n",
      "[147.29 - 147.73] hobby\n",
      "[147.77 - 148.29] and\n",
      "[148.35 - 148.63] spend\n",
      "[148.69 - 148.94] time\n",
      "[149.00 - 149.10] with\n",
      "[149.16 - 149.36] your\n",
      "[149.42 - 149.86] pet\n",
      "[150.20 - 150.28] or\n",
      "[150.32 - 151.06] even\n",
      "[151.14 - 151.28] you\n",
      "[151.32 - 151.52] can\n",
      "[151.60 - 152.00] visit\n",
      "[152.06 - 152.12] a\n",
      "[152.16 - 152.60] spa\n",
      "[152.64 - 153.88] and\n",
      "[153.86 - 154.10] That\n",
      "[154.18 - 154.36] could\n",
      "[154.42 - 154.56] make\n",
      "[154.59 - 154.60] a\n",
      "[154.81 - 155.09] very\n",
      "[155.15 - 155.31] good\n",
      "[155.39 - 155.79] difference.\n",
      "[155.97 - 156.07] And\n",
      "[156.17 - 156.31] for\n",
      "[156.37 - 156.51] me,\n",
      "[156.65 - 156.73] I\n",
      "[156.79 - 156.97] like\n",
      "[157.01 - 157.15] to\n",
      "[157.25 - 157.49] play\n",
      "[157.57 - 158.09] piano\n",
      "[158.15 - 158.31] when\n",
      "[158.45 - 158.55] I\n",
      "[158.72 - 158.97] feel\n",
      "[159.00 - 159.52] stressed\n",
      "[159.74 - 159.84] and\n",
      "[159.92 - 160.40] sometimes\n",
      "[160.42 - 160.44] I\n",
      "[160.62 - 160.74] may\n",
      "[160.78 - 160.96] just\n",
      "[161.90 - 162.20] watch\n",
      "[162.36 - 162.68] some\n",
      "[163.04 - 163.47] movies\n",
      "[163.53 - 163.65] that\n",
      "[163.71 - 163.85] make\n",
      "[163.89 - 163.99] me\n",
      "[164.07 - 164.33] laugh\n",
      "[164.39 - 164.43] a\n",
      "[164.47 - 164.73] lot.\n",
      "[165.57 - 165.69] And\n",
      "[165.73 - 165.83] the\n",
      "[165.89 - 166.15] next\n",
      "[166.17 - 166.31] word\n",
      "[166.47 - 166.57] is\n",
      "[167.00 - 167.16] E.\n",
      "[167.68 - 167.76] E\n",
      "[167.88 - 167.98] is\n",
      "[168.12 - 168.48] about\n",
      "[168.58 - 169.98] expectations.\n",
      "[169.96 - 170.40] And\n",
      "[170.42 - 170.44] I\n",
      "[171.20 - 171.40] think\n",
      "[171.52 - 171.75] be\n",
      "[172.33 - 173.05] realistic\n",
      "[173.37 - 173.59] about\n",
      "[173.63 - 174.17] yourself\n",
      "[174.97 - 175.11] is\n",
      "[175.23 - 175.43] to\n",
      "[175.59 - 175.85] true\n",
      "[175.91 - 176.03] to\n",
      "[176.09 - 176.71] yourself\n",
      "[176.75 - 177.83] and\n",
      "[177.95 - 178.23] others.\n",
      "[178.85 - 179.08] So\n",
      "[179.28 - 179.36] you\n",
      "[179.40 - 179.54] can\n",
      "[179.60 - 179.76] just\n",
      "[179.86 - 180.02] do\n",
      "[180.08 - 180.24] your\n",
      "[180.30 - 180.62] best\n",
      "[180.82 - 180.90] and\n",
      "[180.96 - 181.50] don't\n",
      "[181.60 - 181.84] try\n",
      "[181.90 - 181.98] to\n",
      "[182.04 - 182.14] be\n",
      "[182.22 - 182.68] perfect\n",
      "[183.26 - 183.34] and\n",
      "[183.38 - 183.64] don't\n",
      "[183.72 - 184.10] expect\n",
      "[184.26 - 184.52] others\n",
      "[184.66 - 184.86] to\n",
      "[184.92 - 185.09] be\n",
      "[185.12 - 185.38] too\n",
      "[185.49 - 185.79] because\n",
      "[185.81 - 186.69] that\n",
      "[186.73 - 186.91] will\n",
      "[186.95 - 187.39] release\n",
      "[188.03 - 188.09] and\n",
      "[188.15 - 188.57] reduce\n",
      "[188.59 - 188.61] a\n",
      "[188.73 - 188.95] lot\n",
      "[189.01 - 189.07] of\n",
      "[189.11 - 189.51] stress\n",
      "[189.97 - 190.13] for\n",
      "[190.19 - 190.41] you\n",
      "[190.43 - 191.07] and\n",
      "[191.11 - 191.23] the\n",
      "[191.27 - 191.53] people\n",
      "[191.59 - 191.85] around\n",
      "[191.91 - 192.70] you.\n",
      "[192.68 - 193.18] And\n",
      "[193.26 - 193.38] the\n",
      "[193.76 - 193.96] next\n",
      "[194.02 - 194.28] word\n",
      "[194.40 - 194.50] is\n",
      "[195.08 - 195.16] S.\n",
      "[195.78 - 195.84] S\n",
      "[196.00 - 196.10] is\n",
      "[196.12 - 196.62] Stanford\n",
      "[196.70 - 197.12] sleep.\n",
      "[197.99 - 198.13] And\n",
      "[198.15 - 198.17] I\n",
      "[198.89 - 199.17] really,\n",
      "[199.21 - 199.45] really\n",
      "[199.51 - 199.69] love\n",
      "[199.73 - 199.85] to\n",
      "[199.91 - 200.21] sleep,\n",
      "[200.25 - 200.29] to\n",
      "[200.59 - 200.67] be\n",
      "[200.71 - 201.07] honest.\n",
      "[201.41 - 201.63] That's\n",
      "[201.71 - 201.91] my\n",
      "[201.99 - 202.56] hobby,\n",
      "[202.57 - 202.59] I\n",
      "[202.62 - 202.84] think.\n",
      "[203.86 - 204.10] Because\n",
      "[204.18 - 204.56] sleep,\n",
      "[204.96 - 205.22] if\n",
      "[205.24 - 205.36] you\n",
      "[205.40 - 205.58] get\n",
      "[205.64 - 205.66] a\n",
      "[205.78 - 205.98] good\n",
      "[206.04 - 206.26] light\n",
      "[206.28 - 206.66] sleep,\n",
      "[207.20 - 207.41] then\n",
      "[207.50 - 207.56] it\n",
      "[207.59 - 207.77] will\n",
      "[207.81 - 207.99] keep\n",
      "[208.03 - 208.23] your\n",
      "[208.27 - 208.57] mind\n",
      "[208.63 - 208.71] and\n",
      "[208.75 - 208.91] your\n",
      "[208.95 - 209.23] body\n",
      "[209.33 - 209.43] in\n",
      "[209.53 - 209.81] shape.\n",
      "[210.97 - 211.11] And\n",
      "[212.13 - 212.51] experts\n",
      "[212.53 - 212.78] say\n",
      "[212.85 - 212.92] if\n",
      "[212.96 - 213.12] you\n",
      "[213.18 - 214.18] sleep,\n",
      "[214.16 - 214.56] more\n",
      "[214.62 - 214.78] than\n",
      "[214.82 - 215.24] seven\n",
      "[215.30 - 215.68] hours,\n",
      "[216.20 - 216.32] you\n",
      "[216.34 - 216.46] will\n",
      "[216.56 - 216.88] actually\n",
      "[216.94 - 217.12] get\n",
      "[217.16 - 217.53] tired.\n",
      "[217.67 - 217.89] So\n",
      "[217.93 - 218.45] don't\n",
      "[218.49 - 218.67] sleep\n",
      "[218.73 - 218.91] too\n",
      "[218.97 - 219.13] much\n",
      "[219.17 - 219.63] in\n",
      "[220.29 - 220.39] the\n",
      "[220.43 - 220.65] day,\n",
      "[221.13 - 221.32] just\n",
      "[221.36 - 221.54] sleep\n",
      "[221.56 - 221.60] it\n",
      "[222.24 - 222.34] when\n",
      "[222.38 - 222.52] you\n",
      "[222.56 - 222.72] feel\n",
      "[222.76 - 223.16] enough.\n",
      "[223.60 - 223.70] And\n",
      "[223.76 - 223.86] the\n",
      "[223.90 - 224.14] last\n",
      "[224.20 - 224.46] word\n",
      "[224.48 - 224.52] is\n",
      "[224.84 - 224.91] S\n",
      "[225.10 - 225.63] again.\n",
      "[225.65 - 225.67] I\n",
      "[227.87 - 228.11] always\n",
      "[228.19 - 228.35] do\n",
      "[228.39 - 228.55] this\n",
      "[228.75 - 229.09] action.\n",
      "[229.44 - 229.54] The\n",
      "[229.68 - 229.76] S\n",
      "[229.78 - 229.98] word\n",
      "[230.06 - 230.14] is\n",
      "[230.24 - 231.44] smile.\n",
      "[231.42 - 231.72] If\n",
      "[231.78 - 231.96] you\n",
      "[232.04 - 232.44] smile\n",
      "[232.84 - 232.96] and\n",
      "[233.02 - 233.32] have\n",
      "[233.42 - 234.00] confidence,\n",
      "[234.41 - 234.59] your\n",
      "[234.69 - 235.09] attitude\n",
      "[235.19 - 235.27] and\n",
      "[235.29 - 235.43] your\n",
      "[235.51 - 235.79] thoughts\n",
      "[236.29 - 236.79] influence\n",
      "[236.85 - 236.95] the\n",
      "[236.99 - 237.21] way\n",
      "[237.23 - 237.51] you\n",
      "[237.57 - 237.75] see\n",
      "[237.85 - 238.15] things.\n",
      "[238.87 - 238.99] And\n",
      "[239.01 - 239.35] if\n",
      "[239.39 - 239.49] you\n",
      "[239.51 - 239.57] are\n",
      "[239.61 - 239.63] a\n",
      "[239.67 - 240.05] negative\n",
      "[240.11 - 240.59] person,\n",
      "[240.65 - 241.51] you\n",
      "[241.55 - 241.71] can\n",
      "[241.87 - 242.27] actually\n",
      "[242.35 - 242.57] learn\n",
      "[242.61 - 242.71] to\n",
      "[242.79 - 243.00] think\n",
      "[243.03 - 243.25] in\n",
      "[243.31 - 243.34] a\n",
      "[243.41 - 243.72] more\n",
      "[243.76 - 244.62] positive\n",
      "[244.68 - 244.84] way\n",
      "[244.92 - 245.26] because\n",
      "[245.66 - 245.80] that\n",
      "[245.88 - 246.06] makes\n",
      "[246.16 - 246.28] you\n",
      "[246.32 - 246.74] feel\n",
      "[246.78 - 247.12] more\n",
      "[247.28 - 247.88] comfortable\n",
      "[247.92 - 248.50] when\n",
      "[248.54 - 248.72] you\n",
      "[248.84 - 248.92] are\n",
      "[249.04 - 249.36] coping\n",
      "[249.40 - 249.54] with\n",
      "[249.62 - 249.72] the\n",
      "[249.74 - 250.24] stress.\n",
      "[250.64 - 251.06] Finally,\n",
      "[251.14 - 251.20] I\n",
      "[251.26 - 251.49] think\n",
      "[251.50 - 251.54] we\n",
      "[251.99 - 252.16] should\n",
      "[252.23 - 252.41] take\n",
      "[252.67 - 253.01] action\n",
      "[253.15 - 253.23] and\n",
      "[253.33 - 253.87] apply\n",
      "[254.45 - 254.63] these\n",
      "[254.77 - 255.07] tips\n",
      "[255.13 - 255.25] to\n",
      "[255.31 - 255.49] your\n",
      "[255.59 - 255.89] life\n",
      "[256.55 - 256.79] so\n",
      "[256.97 - 257.37] everyone\n",
      "[257.45 - 257.65] can\n",
      "[257.71 - 257.81] be\n",
      "[257.83 - 258.59] stressed.\n",
      "[265.75 - 265.99] This\n",
      "[266.03 - 266.47] recording\n",
      "[266.51 - 266.57] is\n",
      "[266.63 - 266.75] from\n",
      "[266.79 - 266.87] the\n",
      "[266.93 - 267.19] British\n",
      "[267.25 - 267.67] Council.\n",
      "[268.29 - 268.39] To\n",
      "[268.45 - 268.71] find\n",
      "[268.83 - 269.03] more\n",
      "[269.09 - 269.63] activities\n",
      "[269.69 - 269.77] to\n",
      "[269.83 - 270.18] practise\n",
      "[270.21 - 270.36] your\n",
      "[270.46 - 270.76] English\n",
      "[271.30 - 271.60] visit\n",
      "[272.06 - 275.29] www.britishcouncil.org\n",
      "[275.63 - 275.93] forward\n",
      "[275.95 - 276.31] slash\n",
      "[276.71 - 276.97] learn\n",
      "[277.11 - 277.71] English.\n",
      "\n",
      "Full Transcript:\n",
      " I want to talk about beating stress today. You know, live here in Hong Kong is very stressful, so I think today's topic is very useful for everyone because we can do something about it just to cope with the stress. So maybe you have some change in your life, maybe big change or small change, but instead of being afraid, I think you should have a positive attitude and think of change as a normal part of life. And I think maybe here in Hong Kong, the family are crafted into a very small housing space. So maybe you will sometimes argue with your family and I think try to resolve the disagreement with people is very important because then you can build strong relationships and keep commitments you have made. For example, sometimes maybe you feel you're feeling alone and you want to make some comfort and I think you can ask the people you trust for help is very important because if you have a bunch of friends they can listen to you then you can release some stress through talking to them. And do you know that actually I find a very funny thing that if you want to reduce some stress, you can reduce it by the word S-T-R-E-S-S, that stress. How about let's begin with the S? Well, I think S is that you can have the scheduling. For example, you don't have to schedule too many things in your day. And if you feel you're too busy, you can cut out an activity or two. And how about the T word? The T word is treat your body well. Because experts say that exercise can reduce stress. And also if you eat healthy food, then your brain and your body get the nourishment they need. And the word is R, the extra is R. R is very important. It says relax. You can do an activity you enjoy or that relaxes you. Maybe you can read a good book or learn a new hobby and spend time with your pet or even you can visit a spa and That could make a very good difference. And for me, I like to play piano when I feel stressed and sometimes I may just watch some movies that make me laugh a lot. And the next word is E. E is about expectations. And I think be realistic about yourself is to true to yourself and others. So you can just do your best and don't try to be perfect and don't expect others to be too because that will release and reduce a lot of stress for you and the people around you. And the next word is S. S is Stanford sleep. And I really, really love to sleep, to be honest. That's my hobby, I think. Because sleep, if you get a good light sleep, then it will keep your mind and your body in shape. And experts say if you sleep, more than seven hours, you will actually get tired. So don't sleep too much in the day, just sleep it when you feel enough. And the last word is S again. I always do this action. The S word is smile. If you smile and have confidence, your attitude and your thoughts influence the way you see things. And if you are a negative person, you can actually learn to think in a more positive way because that makes you feel more comfortable when you are coping with the stress. Finally, I think we should take action and apply these tips to your life so everyone can be stressed. This recording is from the British Council. To find more activities to practise your English visit www.britishcouncil.org forward slash learn English.\n",
      "\n",
      "Number of sentences: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 6/6 [00:02<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (42, 768)\n",
      "Adaptive threshold used: 0.17107978\n",
      "Predicted segments: [0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 9, 9, 9, 9, 10, 10, 10, 10]\n",
      "\n",
      "--- Segments & Topics ---\n",
      "\n",
      "Segment 0:\n",
      "Text: I want to talk about beating stress today You know, live here in Hong Kong is very stressful, so I think today's topic is very useful for everyone because we can do something about it just to cope with the stress\n",
      "Topic phrase: stress\n",
      "\n",
      "Segment 1:\n",
      "Text: So maybe you have some change in your life, maybe big change or small change, but instead of being afraid, I think you should have a positive attitude and think of change as a normal part of life And I think maybe here in Hong Kong, the family are crafted into a very small housing space\n",
      "Topic phrase: change\n",
      "\n",
      "Segment 2:\n",
      "Text: So maybe you will sometimes argue with your family and I think try to resolve the disagreement with people is very important because then you can build strong relationships and keep commitments you have made For example, sometimes maybe you feel you're feeling alone and you want to make some comfort and I think you can ask the people you trust for help is very important because if you have a bunch of friends they can listen to you then you can release some stress through talking to them And do you know that actually I find a very funny thing that if you want to reduce some stress, you can reduce it by the word S-T-R-E-S-S, that stress How about let's begin with the S Well, I think S is that you can have the scheduling For example, you don't have to schedule too many things in your day And if you feel you're too busy, you can cut out an activity or two\n",
      "Topic phrase: the scheduling\n",
      "\n",
      "Segment 3:\n",
      "Text: And how about the T word The T word is treat your body well Because experts say that exercise can reduce stress And also if you eat healthy food, then your brain and your body get the nourishment they need\n",
      "Topic phrase: the T word\n",
      "\n",
      "Segment 4:\n",
      "Text: And the word is R, the extra is R R is very important It says relax You can do an activity you enjoy or that relaxes you Maybe you can read a good book or learn a new hobby and spend time with your pet or even you can visit a spa and That could make a very good difference And for me, I like to play piano when I feel stressed and sometimes I may just watch some movies that make me laugh a lot\n",
      "Topic phrase: R\n",
      "\n",
      "Segment 5:\n",
      "Text: And the next word is E E is about expectations And I think be realistic about yourself is to true to yourself and others So you can just do your best and don't try to be perfect and don't expect others to be too because that will release and reduce a lot of stress for you and the people around you\n",
      "Topic phrase: expectations\n",
      "\n",
      "Segment 6:\n",
      "Text: And the next word is S S is Stanford sleep And I really, really love to sleep, to be honest That's my hobby, I think\n",
      "Topic phrase: my hobby\n",
      "\n",
      "Segment 7:\n",
      "Text: Because sleep, if you get a good light sleep, then it will keep your mind and your body in shape And experts say if you sleep, more than seven hours, you will actually get tired So don't sleep too much in the day, just sleep it when you feel enough\n",
      "Topic phrase: a good light sleep\n",
      "\n",
      "Segment 8:\n",
      "Text: And the last word is S again I always do this action\n",
      "Topic phrase: this action\n",
      "\n",
      "Segment 9:\n",
      "Text: The S word is smile If you smile and have confidence, your attitude and your thoughts influence the way you see things And if you are a negative person, you can actually learn to think in a more positive way because that makes you feel more comfortable when you are coping with the stress Finally, I think we should take action and apply these tips to your life so everyone can be stressed\n",
      "Topic phrase: a more positive way\n",
      "\n",
      "Segment 10:\n",
      "Text: This recording is from the British Council To find more activities to practise your English visit www britishcouncil org forward slash learn English\n",
      "Topic phrase: www britishcouncil org\n"
     ]
    }
   ],
   "source": [
    "import whisperx\n",
    "import time\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "\n",
    "# 1. Audio transcription\n",
    "\n",
    "audio_file = \"En.m4a\"\n",
    "device = \"cpu\"\n",
    "\n",
    "model_whisper = whisperx.load_model(\"small\", device=device, compute_type=\"float32\")\n",
    "start_time = time.time()\n",
    "result = model_whisper.transcribe(audio_file)\n",
    "end_time = time.time()\n",
    "\n",
    "alignment_model, align_metadata = whisperx.load_align_model(\n",
    "    language_code=result[\"language\"], device=device\n",
    ")\n",
    "\n",
    "audio, sr = librosa.load(audio_file, sr=16000, mono=True)\n",
    "duration_sec = len(audio) / sr\n",
    "print(f\"Loaded audio sr={sr}, duration={duration_sec:.2f}s\")\n",
    "\n",
    "result_aligned = whisperx.align(\n",
    "    transcript=result[\"segments\"],\n",
    "    model=alignment_model,\n",
    "    align_model_metadata=align_metadata,\n",
    "    audio=audio,\n",
    "    device=device,\n",
    "    return_char_alignments=False\n",
    ")\n",
    "\n",
    "# 2. Prepare transcript & sentences\n",
    "\n",
    "word_segments = result_aligned[\"word_segments\"]\n",
    "for word in word_segments:\n",
    "    print(f\"[{word['start']:.2f} - {word['end']:.2f}] {word['word'].strip()}\")\n",
    "\n",
    "transcript_text = \" \".join([w['word'].strip() for w in word_segments])\n",
    "transcript_text = \" \".join(transcript_text.split())\n",
    "print(\"\\nFull Transcript:\\n\", transcript_text)\n",
    "\n",
    "sentences = [s.strip() for s in transcript_text.replace(\"?\", \".\").replace(\"!\", \".\").split(\".\") if s.strip()]\n",
    "print(f\"\\nNumber of sentences: {len(sentences)}\")\n",
    "\n",
    "# 3. Sentence embeddings\n",
    "\n",
    "model_sent = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "embeddings = model_sent.encode(sentences, batch_size=8, show_progress_bar=True)\n",
    "print(\"Embeddings shape:\", embeddings.shape)\n",
    "\n",
    "# 4. Adaptive topic segmentation\n",
    "\n",
    "def adaptive_threshold_segmentation(embeddings, method=\"std\", min_size=2, std_factor=1.0, percentile=20):\n",
    "    num_sentences = embeddings.shape[0]\n",
    "    sims = [cosine_similarity(embeddings[i-1].reshape(1,-1), embeddings[i].reshape(1,-1))[0][0] \n",
    "            for i in range(1, num_sentences)]\n",
    "    sims = np.array(sims)\n",
    "\n",
    "    if method == \"std\":\n",
    "        threshold = sims.mean() - std_factor * sims.std()\n",
    "    elif method == \"percentile\":\n",
    "        threshold = np.percentile(sims, percentile)\n",
    "    else:\n",
    "        raise ValueError(\"method must be 'std' or 'percentile'\")\n",
    "\n",
    "    pred_segments = [0]\n",
    "    current_segment = 0\n",
    "    last_boundary = 0\n",
    "\n",
    "    for i in range(1, num_sentences):\n",
    "        sim = cosine_similarity(embeddings[i-1].reshape(1,-1), embeddings[i].reshape(1,-1))[0][0]\n",
    "        if sim < threshold and (i - last_boundary) >= min_size:\n",
    "            current_segment += 1\n",
    "            last_boundary = i\n",
    "        pred_segments.append(current_segment)\n",
    "\n",
    "    return pred_segments, threshold\n",
    "\n",
    "pred_segments, used_threshold = adaptive_threshold_segmentation(\n",
    "    embeddings, method=\"percentile\", percentile=30, min_size=2\n",
    ")\n",
    "print(\"Adaptive threshold used:\", used_threshold)\n",
    "print(\"Predicted segments:\", pred_segments)\n",
    "\n",
    "\n",
    "# 5. Extract topic phrases\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def segment_topic_phrase(sentences, segments, sentence_embeddings, top_n=1):\n",
    "    segment_dict = {}\n",
    "    unique_segments = sorted(set(segments))\n",
    "\n",
    "    for seg_id in unique_segments:\n",
    "        indices = [i for i, seg in enumerate(segments) if seg == seg_id]\n",
    "        if not indices:\n",
    "            continue\n",
    "\n",
    "        seg_emb = sentence_embeddings[indices].mean(axis=0, keepdims=True)\n",
    "        seg_text = \" \".join([sentences[i] for i in indices])\n",
    "        doc = nlp(seg_text)\n",
    "        candidates = [chunk.text for chunk in doc.noun_chunks if len(chunk.text.split()) <= 4]\n",
    "\n",
    "        if not candidates:\n",
    "            segment_dict[seg_id] = [\"[no phrase found]\"]\n",
    "            continue\n",
    "\n",
    "        candidate_embeddings = model_sent.encode(candidates, convert_to_numpy=True)\n",
    "        sims = cosine_similarity(seg_emb, candidate_embeddings)[0]\n",
    "        top_indices = sims.argsort()[::-1][:top_n]\n",
    "        top_phrases = [candidates[i] for i in top_indices]\n",
    "\n",
    "        segment_dict[seg_id] = top_phrases\n",
    "\n",
    "    return segment_dict\n",
    "\n",
    "segment_phrases = segment_topic_phrase(sentences, pred_segments, embeddings)\n",
    "\n",
    "# 6. Output results\n",
    "\n",
    "print(\"\\n--- Segments & Topics ---\")\n",
    "for seg_id, phrases in segment_phrases.items():\n",
    "    seg_text = \" \".join([sentences[i] for i, seg in enumerate(pred_segments) if seg == seg_id])\n",
    "    print(f\"\\nSegment {seg_id}:\")\n",
    "    print(f\"Text: {seg_text}\")\n",
    "    print(f\"Topic phrase: {phrases[0]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3223a0fa",
   "metadata": {},
   "source": [
    "This is the output of everything put together so I get a transcription with timestamps, the text is segmented into topics and these topics also have names. In the following chunk I am going to test out how semantic serach works based on transformer embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efa36a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "def search_topic(query, sentences, segments, sentence_embeddings, segment_phrases, model):\n",
    "    \"\"\"\n",
    "    Returns the best-matching topic (segment) for a query.\n",
    "    \"\"\"\n",
    "    query_emb = model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "    unique_segments = sorted(set(segments))\n",
    "    segment_scores = []\n",
    "    for seg_id in unique_segments:\n",
    "        indices = [i for i, seg in enumerate(segments) if seg == seg_id]\n",
    "        if not indices:\n",
    "            continue\n",
    "        seg_emb = sentence_embeddings[indices].mean(axis=0, keepdims=True)\n",
    "        score = util.cos_sim(query_emb, torch.tensor(seg_emb)).item()\n",
    "        segment_scores.append((seg_id, score))\n",
    "\n",
    "    best_seg_id, best_score = max(segment_scores, key=lambda x: x[1])\n",
    "    best_text = \" \".join([sentences[i] for i, seg in enumerate(segments) if seg == best_seg_id])\n",
    "    best_phrase = segment_phrases.get(best_seg_id, [\"[no phrase found]\"])[0]\n",
    "\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    print(f\"Best matching segment ID: {best_seg_id}\")\n",
    "    print(f\"Segment topic phrase: {best_phrase}\")\n",
    "    print(f\"Similarity score: {best_score:.4f}\")\n",
    "    print(f\"\\nSegment text:\\n{best_text}\")\n",
    "\n",
    "    return best_seg_id, best_text, best_phrase, best_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27d3bf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: health\n",
      "Best matching segment ID: 3\n",
      "Segment topic phrase: the T word\n",
      "Similarity score: 0.4734\n",
      "\n",
      "Segment text:\n",
      "And how about the T word The T word is treat your body well Because experts say that exercise can reduce stress And also if you eat healthy food, then your brain and your body get the nourishment they need\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " 'And how about the T word The T word is treat your body well Because experts say that exercise can reduce stress And also if you eat healthy food, then your brain and your body get the nourishment they need',\n",
       " 'the T word',\n",
       " 0.47340062260627747)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"health\"\n",
    "search_topic(query, sentences, pred_segments, embeddings, segment_phrases, model_sent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f98c218",
   "metadata": {},
   "source": [
    "The results shows a decent similarity score and a semantically close part of the text, however, it is a bit long and it may not be the best possible option to present in to the user in the application. I would also like to try out another way for semantic search with a pretrained model and see what the results can tell me. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0014c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: work\n",
      "\n",
      "Best matching sentence:\n",
      " I look formard to finish it and see the end product.\n",
      "\n",
      "Similarity score: 0.3232\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import json \n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "df = pd.read_csv(\"topics.csv\")\n",
    "\n",
    "sentences = []\n",
    "for s in df[\"sentences\"].dropna():\n",
    "    sentences.extend(json.loads(s))\n",
    "\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "sentence_embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "\n",
    "query = \"work\"\n",
    "query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "cosine_scores = util.cos_sim(query_embedding, sentence_embeddings)\n",
    "\n",
    "top_idx = torch.argmax(cosine_scores)\n",
    "best_sentence = sentences[top_idx]\n",
    "best_score = cosine_scores[0][top_idx].item()\n",
    "\n",
    "print(f\"\\nQuery: {query}\")\n",
    "print(f\"\\nBest matching sentence:\\n{best_sentence}\")\n",
    "print(f\"\\nSimilarity score: {best_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43734d54",
   "metadata": {},
   "source": [
    "Here, we see a lower similarity score, however it would still be the highest one matching the query. What I like in this result is that it is shorter and still matches the idea of the query.\n",
    "\n",
    "### Semantic search is still due reserach and exploration and it will be done in the following weeks since for now it has low priority."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
